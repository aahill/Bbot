#+TITLE:Braitenbot Code 
#+AUTHOR: Jake Brawer, Aaron Hill
#+EMAIL: jabrawer@vassar.edu, aahill@vassar.edu
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+BABEL: :session *python* :cache yes :results output graphics :exports both :tangle yes 
* Assorted Notes
** Why development? (According to Josh Bongard)*

Mutations that manifest early in development have a greater affect than mutations that happen later
- thus evolution can confer big medium or small changes, due to development.
  - "Smallerer changes are more likely to be beneficial"
** TODO Ask John and Ken about:
*** What do we do about lack of variation in later generations??
* What needs to be done
** TODO Tweak is_viable algorithm
Are we really generating "viable" organisms?
* This Document Or: How I Learned to Stop Worrying And Love Emacs 
 This document, created using Emacs' org-mode is an example of a [[https://en.wikipedia.org/wiki/Literate_programming][literate program]]. Briefly, a literate program intersperses plain prose amongst snippets of runnable code. The result is a program that is both human-readbale and, due to its inherent modularity, easily testable.\\
 \vspace

 Additionally, Emacs will automatically export the file to a Latex formated PDF or HTML file for easier human consumption. Going forward I will attempt to maintain and update this document as the main hub of the Braitenbot project.

* What I Did This Summer
\indent Much of the summer was spent fixing, adding to, and validating the code. Here is a small list of a few of the changes that were made:
- Decoder instructions are no longer duples, now 3-tuples, with the third element specifying the origin of the sucessive wire.
- Fixed error that resulted in threads having incomplete wire connections.
- Altered the behavior of certain methods/classes including InstructionSet, reprodue, Organism, etc (see corresponding section is this document).
- Wrote the algorithm [[*RankAndCrossGeneration][RankAndCrossGeneration]] (and its variants) which ranks organisms in a generation based on their relative performances and crosses them accordingly.
- Other bug fixes and tweaks

A large chunk of my time was spent specifying and validating the code. I have included these in this document, but this is still a work in progress. Now that the code is in a more modular format the code can be tested more easily and therefore more robust test can be administered.\\
\vspace

Probably most importantly, we devised a hypothesis and a corresponing experiment:\\

\hangindent =0.7cm H_1: The distribution of crossover points is realted to the robustness of an organism's traits, and thus, is directly related to evolvability, fitness, and modualrity.\\
\vspace 

This could be tested by running at least two populations. Both populations would initially contain organisms with the same number of crossover points, but in one population they could be at any locus on the genome, while in the other population they would be restricted to the
 intergenomic regions. One might predict that the latter population would have an advantage due to potentially adaptive genes to be transmitted intact to successive generations.\\

** What I learned  
I ran many populations in simulation, selecting for organism containing the highest number of
'functional threads', i.e. threads that code for actual wires (thus, I didn't need to run actual robots.
Populations differed in terms of a few key parameters, i.e. crossover rate and mutation rate. 
Below are the results of each paramter group (Each group representing the average of 3 populations).\\
   

#+RESULTS:
[[file:/home/jake/org/selection-comparison-1.png]]

Here's what I take away from these results:
- Due to many factors, including small population size,there is not
 much variation in the population
  - This is mitigated in part by a very high mutation rate (An order of magnitude larger than the default)
- Very high mutation rates are required because of the large amount of noncoding DNA
  - Likewise, more adding more crossover points may not affect performance significantly 
due to being distributed amongst noncoding regions.

* Next steps
The most obvious next step would be to decrease the size of the noncoding regions
 (by decreasing thread size) and to run these experiments again and compare the results. 
There experiments would also help decide which parameters to use when running the actual robot.\\
\vspace

Additionally, before any physical expeirments are run, I would like to complete this document, 
including better comments and more robust validation tests.\\

\vspace
I also think we need to look/tweak the algorithm that generates "viable" organisms to make sure
it is giving us what we want.
* Pin and Pin Group Code
#+BEGIN_SRC python :noweb yes :tangle PinAndPinGroup.py
<<Imports>>
<<Pin>>

<<PinGroup>>

<<MotorSensorPinGroup>>

<<Group1>>

<<Group2>>

<<Group3>>

<<Group4>>

<<Group5>>

<<Group6>>

<<MotorSensorGroups>>

#+END_SRC
** Imports
#+NAME: Imports
#+BEGIN_SRC python :noweb yes 
import random

#+END_SRC
** Class: Pin
*Input:* group_id, a string the name of the pin group \\
   number, an int, the pin number\\
*Output:*  A Pin object with attributes group_id, number and availability (a bool).

#+NAME: Pin
#+BEGIN_SRC python 
  class Pin:
      # group_id represents the group the pin belongs to
      # number identifies the pin number within the group
      def __init__(self, group_id, number, group):
          self.group_id = group_id
          self.number = number
          #self.group = group
          self.available = True

      def setAvailability(self, bool):
          self.available = bool


#+END_SRC

*** Test:
#+BEGIN_SRC python :noweb yes :results output 
  <<Pin>>

  p = pin(3,4,5)
  print p.group_id
  print p.number 

#+END_SRC

#+RESULTS:
: 3
: 4

** Class: PinGroup
*Input:* None\\
*Output:* PinGroup object\\
#+NAME: PinGroup
#+BEGIN_SRC python :noweb yes 
  class PinGroup(object):
      def __call__(self):
          return self
          
      def __init__(self):
          self.type = None

      def get_input(self, pin_index):
          raise NotImplementedError

      def get_output(self, pin_index):
          raise NotImplementedError

      def get_random_input(self):
          raise NotImplementedError

      def get_random_output(self):
          raise NotImplementedError

      <<match_and_remove_pin>>

#+END_SRC 


*** Methods
*Input:* pin, a Pin object
    pin_list1, a list containing pins
    pin_list2, a list containing pins
*Output:* None
*Side Effect:* Checks to see if pin is in either pin_lists. If so, it sets the availability of the matching pin in either list to false.

#+NAME: match_and_remove_pins
#+BEGIN_SRC python :noweb-ref match_and_remove_pin  :results output
  def match_and_remove_pin(self, pin, pin_list1, pin_list2=None):
      pin_found = False
      for x in range(len(pin_list1)):
          if pin.group_id == pin_list1[x].group_id and pin.number == pin_list1[x].number:
              pin_found = True
              # NOTE: instead of deleting the pin from the list, the pin's available variable will be set to false.
              # this allows for the ability to determine if a pin is 'taken' by another thread
              pin_list1[x].setAvailability(False)
              break

      if not pin_found and pin_list2 is not None:
          for x in range(len(pin_list2)):
              # None types in the pin list signify pins that are no longer available, and should be skipped over
              if pin_list2[x] is not None:
                  if pin.group_id == pin_list2[x].group_id and pin.number == pin_list2[x].number:
                      pin_found = True
                      # NOTE: instead of deleting the pin from the list, the pin's available variable will be set to false.
                      # this allows for the ability to determine if a pin is 'taken' by another thread
                      pin_list2[x].setAvailability(False)
                      break
      if pin_found is False:
          pass
      assert pin_found is True


  #NOTE: I(nhibitory) and E(xcitatory) are inputs
      # N and T(hreshold) are outputs

#+END_SRC


#+RESULTS:

**** Test 
#+BEGIN_SRC python :noweb yes :results output :tangle testy.py
  # Need these to test match_and_remove_pins
  <<Pin>>
  <<PinGroup>> 
   
  pin1 = pin(2,1,1)
  pin2 = pin(1,3,4)
  piny = pin(1,1,1) #piny is identical to pin1, thus pin1 should be made unavailable
  pingroup= PinGroup()

  list1 = [pin2, pin1]
  print "pin1 avaialability before match_and_remove is called:", pin1.available 
  pingroup.match_and_remove_pin(piny, list1)
  print "Pin1 availability after:", pin1.available 

#+END_SRC

#+RESULTS:
: pin1 avaialability before match_and_remove is called: True
: Pin1 availability after: True

** Class: MotorSensorPinGroup
#+NAME: MotorSensorPinGroup
#+BEGIN_SRC python :noweb yes 

class MotorSensorPinGroup(PinGroup):
    def __init__(self):
        #PinGroup.__init__(self)
        super(PinGroup, self).__init__()
        self.pins = None

    def get_input(self, pin_index):
        target_pin = self.pins[pin_index]
        #print target_pin
        #self.match_and_remove(target_pin, self.pins)
        if target_pin.available == False:
            raise IndexError
        else:
            self.call_match_and_remove_pin(target_pin, self.pins)
        return target_pin

    def get_output(self, pin_index):
        target_pin = self.pins[pin_index]
        #self.match_and_remove(target_pin, self.pins)
        if target_pin.available ==False:
            raise IndexError
        else:
            self.call_match_and_remove_pin(target_pin, self.pins)
        return target_pin

    def get_random_input(self):
        target_pin = random.choice([pin for pin in self.pins if pin.available is True])
        #self.match_and_remove(target_pin, self.pins)
        self.call_match_and_remove_pin(target_pin, self.pins)
        return target_pin

    def get_random_output(self):
        target_pin = random.choice([pin for pin in self.pins if pin.available is True])
        #self.match_and_remove(target_pin, self.pins)
        self.call_match_and_remove_pin(target_pin, self.pins)
        return target_pin

    def call_match_and_remove_pin(self, pin, pin_list1, pin_list2=None):
        super(MotorSensorPinGroup, self).match_and_remove_pin(pin, pin_list1, pin_list2)

#+END_SRC
** Specific PinGroups
Componenets on the Braitenbot are broken up into different PinGroups. Groups1-6 correspond to the 6 neurons
*** Class:Group1  
#+NAME: Group1
#+BEGIN_SRC python
class Group1(PinGroup):
    def __init__(self):
        #PinGroup.__init__(self)
        super(PinGroup, self).__init__()
        self.type = "standard"
        # list of available pins in group e1
        self.e1 = [Pin("e1", i, self) for i in range(4)]
        self.i1 = [Pin("i2", i, self) for i in range(3)]
        self.n1 = [Pin("n1", i, self) for i in range(4)]

    def get_input(self, pin_index):
        all_inputs = self.e1 + self.i1
        target_pin = all_inputs[pin_index]
        target_pin.available = False
        #self.match_and_remove(target_pin, self.e1, self.i1)
        self.call_match_and_remove_pin(target_pin, self.e1, self.i1)
        return target_pin

    def get_output(self, pin_index):
        target_pin = self.n1[pin_index]
        #self.match_and_remove(target_pin, self.n1)
        self.call_match_and_remove_pin(target_pin, self.n1)
        return target_pin

    """
    gets a random available input pin
    """
    def get_random_input(self):
        # put all available pins in a list
        available_inputs = [pin for pin in self.e1 + self.i1 if pin.available is True]
        target_pin = random.choice(available_inputs)
        self.call_match_and_remove_pin(target_pin, self.e1, self.i1)
        return target_pin

    def get_random_output(self):
        # put all available pins in a list
        target_pin = random.choice([pin for pin in self.n1 if pin.available is True])
        self.call_match_and_remove_pin(target_pin, self.n1)
        return target_pin

    def call_match_and_remove_pin(self, pin, pin_list1, pin_list2=None):
        super(Group1, self).match_and_remove_pin(pin, pin_list1, pin_list2)
#+END_SRC

*** Class:Group2
#+NAME: Group2
#+BEGIN_SRC python :noweb yes 

class Group2(PinGroup):
    def __init__(self):
        super(PinGroup, self).__init__()
        self.type = "standard"
        # list of available pins in group 2
        self.e2 = [Pin("e2", i, self) for i in range(4)]
        self.i2 = [Pin("i2", i, self) for i in range(3)]
        self.n2 = [Pin("n2", i, self) for i in range(4)]

    def get_input(self, pin_index):
        all_inputs = self.e2 + self.i2
        target_pin = all_inputs[pin_index]
        self.call_match_and_remove_pin(target_pin, self.e2, self.i2)
        return target_pin

    def get_output(self, pin_index):
        target_pin = self.n2[pin_index]
        self.call_match_and_remove_pin(target_pin, self.n2)
        return target_pin

    """
    return a random available input
    """
    def get_random_input(self):
        # put all available pins in a list
        available_inputs = [pin for pin in self.e2 + self.i2 if pin.available is True]
        target_pin = random.choice(available_inputs)
        self.call_match_and_remove_pin(target_pin, self.e2, self.i2)
        return target_pin

    """
    return a random available output
    """
    def get_random_output(self):
        # put all available pins in a list
        target_pin = random.choice([pin for pin in self.n2 if pin.available is True])
        self.call_match_and_remove_pin(target_pin, self.n2)
        return target_pin

    def call_match_and_remove_pin(self, pin, pin_list1, pin_list2=None):
        super(Group2, self).match_and_remove_pin(pin, pin_list1, pin_list2)
#+END_SRC 
*** Class:Group3
#+NAME: Group3
#+BEGIN_SRC python 
class Group3(PinGroup):
    def __init__(self):
        super(PinGroup, self).__init__()
        self.type = "standard"
        # list of available pins in group 3
        self.e3 = [Pin("e3", i, self) for i in range(4)]
        self.i3 = [Pin("i3", i, self) for i in range(3)]
        self.t3 = [Pin("t3", i, self) for i in range(4)]
        self.n3 = [Pin("n3", i, self) for i in range(4)]

    def get_input(self, pin_index):
        all_inputs = self.e3 + self.i3
        target_pin = all_inputs[pin_index]
        self.call_match_and_remove_pin(target_pin, self.e3, self.i3)
        return target_pin

    def get_output(self, pin_index):
        all_outputs = self.n3 + self.t3
        target_pin = all_outputs[pin_index]
        self.call_match_and_remove_pin(target_pin, self.n3, self.t3)
        return target_pin

    """
    returns a random available input
    """
    def get_random_input(self):
        available_inputs = [pin for pin in self.e3 + self.i3 if pin.available is True]
        target_pin = random.choice(available_inputs)
        self.call_match_and_remove_pin(target_pin, self.e3, self.i3)
        return target_pin

    """
    returns a random available input
    """
    def get_random_output(self):
        available_outputs = [pin for pin in self.n3 + self.t3 if pin.available is True]
        target_pin = random.choice(available_outputs)
        self.call_match_and_remove_pin(target_pin, self.n3, self.t3)
        return target_pin

    def call_match_and_remove_pin(self, pin, pin_list1, pin_list2=None):
        super(Group3, self).match_and_remove_pin(pin, pin_list1, pin_list2)
#+END_SRC
*** Class:Group4
#+NAME: Group4
#+BEGIN_SRC python :noweb yes
class Group4(PinGroup):
    def __init__(self):
        #PinGroup.__init__(self)
        super(PinGroup, self).__init__()
        self.type = "standard"
        # list of available pins in group 4
        self.e4 = [Pin("e4", i, self) for i in range(4)]
        self.i4 = [Pin("i4", i, self) for i in range(3)]
        self.t4 = [Pin("t4", i, self) for i in range(4)]
        self.n4 = [Pin("n4", i, self) for i in range(4)]

    def get_input(self, pin_index):
        all_inputs = self.e4 + self.i4
        target_pin = all_inputs[pin_index]
        #self.match_and_remove(target_pin, self.e4, self.i4)
        self.call_match_and_remove_pin(target_pin, self.e4, self.i4)
        return target_pin

    def get_output(self, pin_index):
        all_outputs = self.n4 + self.t4
        target_pin = all_outputs[pin_index]
        #self.match_and_remove(target_pin, self.n4, self.t4)
        self.call_match_and_remove_pin(target_pin, self.n4, self.t4)
        return target_pin

    """
    returns a random available input
    """
    def get_random_input(self):
        available_inputs = [pin for pin in self.e4 + self.i4 if pin.available is True]
        target_pin = random.choice(available_inputs)
        self.call_match_and_remove_pin(target_pin, self.e4, self.i4)
        return target_pin

    """
    returns a random available input
    """
    def get_random_output(self):
        available_outputs = [pin for pin in self.n4 + self.t4 if pin.available is True]
        target_pin = random.choice(available_outputs)
        self.call_match_and_remove_pin(target_pin, self.n4, self.t4)
        return target_pin

    def call_match_and_remove_pin(self, pin, pin_list1, pin_list2=None):
        super(Group4, self).match_and_remove_pin(pin, pin_list1, pin_list2)


#+END_SRC
*** Class:Group5
#+NAME:Group5
#+BEGIN_SRC python :noweb yes 
class Group5(PinGroup):
    def __init__(self):
        #PinGroup.__init__(self)
        super(PinGroup, self).__init__()
        self.type = "standard"
        # list of available pins in group 5
        self.e5 = [Pin("e5", i, self) for i in range(4)]
        self.i5 = [Pin("i5", i, self) for i in range(3)]
        self.t5 = [Pin("t5", i, self) for i in range(4)]
        self.n5 = [Pin("n5", i, self) for i in range(4)]

    def get_input(self, pin_index):
        all_inputs = self.e5 + self.i5
        target_pin = all_inputs[pin_index]
        #self.match_and_remove(target_pin, self.e5, self.i5)
        self.call_match_and_remove_pin(target_pin, self.e5, self.i5)
        return target_pin

    def get_output(self, pin_index):
        all_outputs = self.n5 + self.t5
        target_pin = all_outputs[pin_index]
        self.call_match_and_remove_pin(target_pin, self.n5, self.t5)
        #self.match_and_remove(target_pin, self.n5, self.t5)
        return target_pin

    """
    returns a random available input
    """
    def get_random_input(self):
        available_inputs = [pin for pin in self.e5 + self.i5 if pin.available is True]
        target_pin = random.choice(available_inputs)
        self.call_match_and_remove_pin(target_pin, self.e5, self.i5)
        return target_pin

    """
    returns a random available input
    """
    def get_random_output(self):
        available_outputs = [pin for pin in self.n5 + self.t5 if pin.available is True]
        target_pin = random.choice(available_outputs)
        self.call_match_and_remove_pin(target_pin, self.n5, self.t5)
        return target_pin

    def call_match_and_remove_pin(self, pin, pin_list1, pin_list2=None):
        super(Group5, self).match_and_remove_pin(pin, pin_list1, pin_list2)
#+END_SRC
*** Class:Group6 
#+NAME: Group6
#+BEGIN_SRC python :noweb yes 
class Group6(PinGroup):

    def __init__(self):
        #pingroup.__init__(self)
        super(PinGroup, self).__init__()
        self.type = "standard"
        # list of available pins in group 6
        self.e6 = [Pin("e6", i, self) for i in range(4)]
        self.i6 = [Pin("i6", i, self) for i in range(3)]
        self.t6 = [Pin("t6", i, self) for i in range(4)]
        self.n6 = [Pin("n6", i, self) for i in range(4)]

    def get_input(self, pin_index):
        all_inputs = self.e6 + self.i6
        target_pin = all_inputs[pin_index]
        #self.match_and_remove(target_pin, self.e6, self.i6)
        self.call_match_and_remove_pin(target_pin, self.e6, self.i6)
        return target_pin

    def get_output(self, pin_index):
        all_outputs = self.n6 + self.t6
        target_pin = all_outputs[pin_index]
        #self.match_and_remove(target_pin, self.n6, self.t6)
        self.call_match_and_remove_pin(target_pin, self.n6, self.t6)
        return target_pin

    """
    returns a random available input
    """
    def get_random_input(self):
        available_inputs = [pin for pin in self.e6 + self.i6 if pin.available is True]
        target_pin = random.choice(available_inputs)
        self.call_match_and_remove_pin(target_pin, self.e6, self.i6)
        return target_pin

    """
    returns a random available input
    """
    def get_random_output(self):
        available_outputs = [pin for pin in self.n6 + self.t6 if pin.available is True]
        target_pin = random.choice(available_outputs)
        self.call_match_and_remove_pin(target_pin, self.n6, self.t6)
        return target_pin

    def call_match_and_remove_pin(self, pin, pin_list1, pin_list2=None):
        super(Group6, self).match_and_remove_pin(pin, pin_list1, pin_list2)

#+END_SRC
*** Classes: Motor And Sensor Groups
#+NAME: MotorSensorGroups
#+BEGIN_SRC python :noweb yes 
class GroupPl(MotorSensorPinGroup):
    def __init__(self):
        #MotorSensorPinGroup.__init__(self)
        super(MotorSensorPinGroup, self).__init__()
        self.pins = [Pin("pl", i, self) for i in range(6)]


class GroupRl(MotorSensorPinGroup):
    def __init__(self):
        #MotorSensorPinGroup.__init__(self)
        super(MotorSensorPinGroup, self).__init__()
        self.pins = [Pin("rl", i, self) for i in range(6)]


class GroupRr(MotorSensorPinGroup):
    def __init__(self):
        #MotorSensorPinGroup.__init__(self)
        super(MotorSensorPinGroup, self).__init__()
        self.pins = [Pin("rr", i, self) for i in range(6)]


class GroupPr(MotorSensorPinGroup):
    def __init__(self):
        #MotorSensorPinGroup.__init__(self)
        super(MotorSensorPinGroup, self).__init__()
        self.pins = [Pin("pr", i, self) for i in range(6)]


class GroupBl(MotorSensorPinGroup):
    def __init__(self):
        #MotorSensorPinGroup.__init__(self)
        super(MotorSensorPinGroup, self).__init__()
        self.pins = [Pin("bl", i, self) for i in range(4)]


class GroupBr(MotorSensorPinGroup):
    def __init__(self):
        #MotorSensorPinGroup.__init__(self)
        super(MotorSensorPinGroup, self).__init__()
        self.pins = [Pin("br", i, self) for i in range(4)]


class GroupFl(MotorSensorPinGroup):
    def __init__(self):
        #MotorSensorPinGroup.__init__(self)
        super(MotorSensorPinGroup, self).__init__()
        self.pins = [Pin("fl", i, self) for i in range(4)]


class GroupFr(MotorSensorPinGroup):
    def __init__(self):
        #MotorSensorPinGroup.__init__(self)
        super(MotorSensorPinGroup, self).__init__()
        self.pins = [Pin("fr", i, self) for i in range(4)]

#+END_SRC

#+RESULTS: MotorSensorGroups

* Decoder Code
#+BEGIN_SRC python :noweb yes :tangle Decoder.py
<<Decoder_Imports>>

<<Decoder>>

#+END_SRC
** Imports
#+NAME: Decoder_Imports
#+BEGIN_SRC python 
import random
from BaseAndInstructionSet import *
#+END_SRC
** Class: Decoder
*Input:* None\\
*Output:* A Decoder object with the attribute index == 1.\\
#+BEGIN_SRC python :noweb yes :tangle Decoder.py
  class Decoder:
      def __init__(self):
          self.index = 0

      <<decode_binary>>

      <<binary_to_decimal>>

      <<generate_coords>>



#+END_SRC
*** Methods
**** decode binary 
*Input:* binary_list, a 4-bit list
*Output:* The corresponding decimal digits for numbers 0-9 only.
#+NAME: decode_binary
#+BEGIN_SRC python 


    def decode_binary(self, binary_list):
        # turn binary list into a string for easy comparison
        binary_string = ""
        for binary_digit in binary_list:
            binary_string += str(binary_digit)

        # determines what number each 4bit binary string represents
        if binary_string == "0000":
            return 0
        elif binary_string == "0001":
            return 1
        elif binary_string == "0010":
            return 2
        elif binary_string == "0011":
            return 3
        elif binary_string == "0100":
            return 4
        elif binary_string == "0101":
            return 5
        elif binary_string == "0110":
            return 6
        elif binary_string == "0111":
            return 7
        elif binary_string == "1000":
            return 8
        elif binary_string == "1001":
            return 9
        elif binary_string == "1010":
            return
        elif binary_string == "1011":
            return
        elif binary_string == "1100":
            return
        elif binary_string == "1101":
            return
        elif binary_string == "1110":
            return
        elif binary_string == "1111":
            return
#+END_SRC
**** binary to decimal 
*Input:* binary_list, an n-bit list
*Output:* A list containing the corresponding decimal digits between 0-9 only.
*Process:* Appends decimal digits to a list calculated by inputting every 4 digits of binary-list into decode_binary.
#+NAME: binary_to_decimal
#+BEGIN_SRC python
    def binary_to_decimal(self, binary_list):
        dec_list = []
        # step through the array in 4s as long as there are enough digits (4) to form a number.
        # this is checked through the expression (len - 4) - (5 % 4)
        #print
        for x in range(0, len(binary_list)-3, 4):
            # generate the list of binary to be decoded
            temp = [binary_list[y] for y in range(x, x+4)]
            dec_list.append(self.decode_binary(temp))
        #    print temp, dec_list 
        #print
        #print 'Hypothetical # of decimal digits: %s/4 = %s. Actual #: %s'% (len(binary_list), len(binary_list)/4, len(dec_list))
        #print
        return dec_list
        #print

#+END_SRC
**** generate coords

*Input:* binaryList, an n-bit list
*Output:* A list of 2- and 3-tuples in the form x,y and x,y,z respectively where the first tuple in the list is a 2-tuple, and the rest are 3-tuples. A given tuples values are dependent upon the values contained within the preceding tuple, in a process outlined more in depth below.
*Side Effect:* decList, a list of decimal and none values used by other methods.

#+NAME: generate_coords
#+BEGIN_SRC python :noweb yes
    def generate_coords(self, binaryList):
        """
        method for getting the next non-NONE value from decList
        return: either the value of decList at index self.index, unless an error is found; in which case
        return -1
        """
        coords = []
        #this value is the height of the matrix created by the pin-group
        #HEIGHT_OF_PINGROUP = 21  -- Not sure why 21 was chosen
        HEIGHT_OF_PINGROUP = 30
        #print binaryList

        <<get_next_val>>

#+END_SRC
***** Submethod: get next val

*Input:* decList, A list of decimal and None values.    
*Output:* Returns the next non-None value in decList, or -1 if an IndexError is raised.
#+NAME: get_next_val
#+BEGIN_SRC python 
        def get_next_val():
            """
            gets the next value from decList, which is the list containing the decimal translation of the binary string
            If this causes an index error, -1 will be returned to avoid the error from halting the program
            :return: the next value form decList
            """
            #print decList
            to_return = None
            try:
                while to_return is None:
                    to_return = decList[self.index]
                    self.index += 1
            except IndexError:
                self.index = -1
                return -1
            #print "index: %s  Next decimal digit: %s" % (self.index, to_return) 
            return to_return
            #print


        # the input decList must have at least one digit for the creation of the initial pin coordinate,
        # and 3 more for the creation of a terminal pin.
        # If this condition is met, generate initial x,y coord from first value in the array
        decList = self.binary_to_decimal(binaryList)
        #print "Direction key: 0: y+=Distance,1:x+=distance, y+=distance, 2:x+=distance, 3:x=distance, y-=distance\n"+\
        #"4:y-=distance, 5:x-=distance, y-=distance, 6: x-=distance, 7: x-=distance, y-=distance"
        #print decList
        if len(decList) < 3:
            return []
        else:
            x = get_next_val()
            # the inital pin coordinate will range from zero to the length of the matrix created by the pin group
            #y = random.randint(0,HEIGHT_OF_PINGROUP)
            y = get_next_val() #Jake addition: no reason we need to selcet randomly. We 
                                # generate perfectly good nonrandom numbers
            #print 'Original (x,y): (%s,%s)' % (x,y)

            # append first xy coordinate in the form of a 2-tuple
           # z = get_next_val() # jake addition: this decides which pin will be the origin
                                # of the subsequent connection
            coords.append((x,y))

            # do the following for every digit after the first (since it was used to generate
            # a starting position)
            # also check for the minimum required digits for the thread instruction process
            while self.index < len(decList):# and (len(decList) - self.index) >= 4:
                # generate the x coordinate's direction, and end pin
                # this number will be 1 through 8, corresponding to the different
                # cardinal directions
                pos1 = get_next_val()
                pos2 = get_next_val()
                pos3 = get_next_val()
                """ try:
                    pos4 = get_next_val() #Jake addition: this decides the origin
                except(IndexError):
                    pass"""
                # the pos1 and pos2 values are used for direction and cannot be negative. Similarly, pos3 is used for
                # distance, and must be greater than 0
                if pos1 < 0 or pos2 < 0 or pos3 <= 0:
                    #print 'Break! a decimal <= 0 was generated'
                    #print 'possible culprits: pos1:%s,pos2:%s,pos3:%s' % (pos1,pos2,pos3)
                    break

                direction = (pos1 + pos2) % 8
                distance = pos3
                if direction == 0:
                    y += distance
                elif direction == 1:
                    y += distance
                    x += distance
                elif direction == 2:
                    x += distance
                elif direction == 3:
                    x += distance
                    y -= distance
                elif direction == 4:
                    y -= distance
                elif direction == 5:
                    y -= distance
                    x -= distance
                elif direction == 6:
                    x -= distance
                elif direction == 7:
                    y += distance
                    x -= distance
                if x < 0 or y < 0:
                    #print 'Break! x or y < 0'
                    #print '(%s,%s)' % (x,y)
                    break
                #print'Direction: (next_val + next_val ) mod 8 --> (%s + %s) mod 8 = %s' % (pos1, pos2, direction)
                #print 'Distance: next_val ---> %s' % distance
                #print 'Direction: %s, Distance: %s --->(%s,%s)' % (direction, distance ,x,y)
               # if self.index in [5 +i*3 for i in range(len(decList))]:
               #Jake addition: adds third coordiante, z :which determines origin
               #of the subsequent wire connection in a thread.
                z = get_next_val()
                if z < 0:
                    #print 'Break! z < 0'
                    #print'z = %s' % z
                    break
                else:
                     coords.append((x,y,z))
                #print
                #print 'Coord z: %s. Final coords: (%s,%s,%s)' % (z,x,y,z)
               # else:
                #    coords.append((x, y))

        #print 'Resultant Coords:', coords
        self.index = 0
        return coords    


#+END_SRC
* Base And InstrutionSet Code
#+BEGIN_SRC python :noweb yes :tangle BaseAndInstructionSet.py
<<BaseAndInstructionSet_Imports>>

<<Base>>

<<InstructionSet>>

#+END_SRC
** Imports
#+NAME: BaseAndInstructionSet_Imports
#+BEGIN_SRC python
import random
import string

#+END_SRC
** Class: Base
*input:* None\\
*Output:* A Base object with two binary attributes, char and crossover_point.Char has $1/2$ chance of being 1 or 0, crossover_point is initialized to 0.\\
#+NAME: Base
#+BEGIN_SRC python 
class Base:
    def __init__(self):
        self.char = random.randint(0, 1)
        self.crossover_point = 0 # Crossover hotspots are set later by InstructionSet
            
    def set_crossover_point(self, new_val):
            self.crossover_point = new_val
            return self.crossover_point

    def set_char(self, new_val):
            self.char = new_val
            return self.char

#+END_SRC
** Class: InstructionSet
*Input:* None\\
*Output:* An InstructionSet object with a genome attribute. A genome is a list containing 2000 Base objects of which at least one has a crossover_point value == 1.\\
#+NAME: InstructionSet
#+BEGIN_SRC python :noweb yes
  class InstructionSet:
      def __init__(self, size, crossover_point_number,unrestricted_distribution, gene_length ):
          self.genome = []
          x = size  # a place holder, the length of the genome
          counter = 0 
          for num in range(0, x ):
              self.genome.append(Base())
              # in the event there are no break points at all
              # maybe we dont want this though? Can discuss later
          if unrestricted_distribution:
              while counter != crossover_point_number:
                  random.choice(self.genome).set_crossover_point(1)
                  counter +=1 
          else:
              potential_locations = [i*gene_length for i in range (1, (len(self.genome)/gene_length)) ]
              while counter != crossover_point_number:
                  rand_index = random.choice(potential_locations)
                  self.genome[rand_index].set_crossover_point(1)
                  potential_locations.remove(rand_index)
                  counter +=1
              print potential_locations
          assert counter == crossover_point_number 
          """for s in self.genome:
              counter += s.crossover_point
          if counter < 1:
              random.choice(self.genome).set_crossover_point(1)"""

      def setGenome(self, new_genome):
          self.genome = new_genome

      <<mutate>>

#+END_SRC

*** Validation
Validating that the various intended properities of an InstructionSet hold
#+BEGIN_SRC python :results output :noweb yes
  <<BaseAndInstructionSet_Imports>>
  <<Base>>
  <<InstructionSet>>

  def instruction_set_test(val,size, crossover_point_num, distro, gene_length):
      print '%s InstructionSets generated, each should have %s crossover points:' % (val, crossover_point_num)
      while val > 0:
          crossover_ps  = 0
          genome = InstructionSet(size, crossover_point_num,distro, gene_length)
          length = len(genome.genome)
          for i in range (len(genome.genome)):
              #print g.char, 
              if genome.genome[i].crossover_point == 1:
                  print '\nCO_point at index: %s' % i
                  crossover_ps += 1
          print
          print 'InstructionSet %s length: %s, # of Crossover_points: %s' % (11 -val, length, crossover_ps)
          print
          val -= 1


  instruction_set_test(10, 20,2, True, 5)
#+END_SRC
#+RESULTS:
#+begin_example
10 InstructionSets generated, each should have 2 crossover points:

CO_point at index: 8

CO_point at index: 13

InstructionSet 1 length: 20, # of Crossover_points: 2


CO_point at index: 0

CO_point at index: 8

InstructionSet 2 length: 20, # of Crossover_points: 2


CO_point at index: 11

CO_point at index: 16

InstructionSet 3 length: 20, # of Crossover_points: 2


CO_point at index: 10

CO_point at index: 15

InstructionSet 4 length: 20, # of Crossover_points: 2


CO_point at index: 5

CO_point at index: 14

InstructionSet 5 length: 20, # of Crossover_points: 2


CO_point at index: 0

CO_point at index: 16

InstructionSet 6 length: 20, # of Crossover_points: 2


CO_point at index: 13

CO_point at index: 18

InstructionSet 7 length: 20, # of Crossover_points: 2


CO_point at index: 1

CO_point at index: 8

InstructionSet 8 length: 20, # of Crossover_points: 2


CO_point at index: 1

CO_point at index: 5

InstructionSet 9 length: 20, # of Crossover_points: 2


CO_point at index: 0

CO_point at index: 9

InstructionSet 10 length: 20, # of Crossover_points: 2

#+end_example

*** Method: mutate
*Input:* Nothing\\
*Output:* None\\
*Side Effect:*Potentially modifies some of the Bases in an InstructionSets genome (char and crossover_point values)\\
*Process:* The algorithm walks through each Base in an InstructionSets genome. For each Base attribute a random int between 0 and mutation_chance is generated. If the random int ==  mutation_chance, the value of that attribute is changed.\\
#+NAME: mutate
#+BEGIN_SRC python 

  def mutate(self):
      #mutation_chance = 20000 #THIS IS THE REAL ONE
      mutation_chance = 20000
      for i in range(len(self.genome)):
          rand_int1 = random.randint(1, mutation_chance)
          rand_int2 = random.randint(1, mutation_chance)
          if rand_int1 == mutation_chance:
              print 'Crossover_point mutation at index: %s' % i
              if self.genome[i].crossover_point == 0:
                  self.genome[i].set_crossover_point(1)
                  print '0 --> %s' % self.genome[i].crossover_point
                  return True
              else:
                  self.genome[i].set_crossover_point(0)
                  print '1 --> %s' % self.genome[i].crossover_point
                  return True
          if rand_int2 == mutation_chance:
              print 'Char mutation at index: %s' % i
              if self.genome[i].char == 0:
                  self.genome[i].set_char(1)
                  print '0 --> %s' % self.genome[i].char
                  return True
              else:
                  self.genome[i].set_char(0) 
                  print '1 --> %s' % self.genome[i].char

#+END_SRC

**** Validation
Vaidatinf that the function mutate mutates and InstructonSet as many times as expected
#+BEGIN_SRC python :noweb yes :results output
  <<BaseAndInstructionSet_Imports>>
  <<Base>>
  <<InstructionSet>>
  def mutation_test(val):
      print 'Results of running mutate %s times ' % val
      genome = InstructionSet(2000, 2, True, 20)
      count = 0
      for i in range (0, val):
          if genome.mutate():
              count += 1
      print 'For each Base in InstructionSet, there is 2/20000 of the Base being mutated.\n There %s bases in an InstructionSet therefore the probability of no mutations taking place is (19998/20000)^2000.\n Thus in %s calls to  mutate there should be  (1 - (19998/20000)^2000)*%s ~ %s mutations.\n  The actual number of mutations: %s' % (2000, val,val, (1- ((19998./20000.)**2000)) * val,count)

  mutation_test(100)
#+END_SRC

#+RESULTS:
#+begin_example
Results of running mutate 100 times 
Char mutation at index: 1731
0 --> 1
Crossover_point mutation at index: 1927
0 --> 1
Char mutation at index: 1016
0 --> 1
Crossover_point mutation at index: 286
0 --> 1
Char mutation at index: 394
1 --> 0
Crossover_point mutation at index: 783
0 --> 1
Char mutation at index: 1730
0 --> 1
Crossover_point mutation at index: 1438
0 --> 1
Crossover_point mutation at index: 423
0 --> 1
Crossover_point mutation at index: 1539
0 --> 1
Char mutation at index: 679
0 --> 1
Crossover_point mutation at index: 1733
0 --> 1
Crossover_point mutation at index: 1841
0 --> 1
Char mutation at index: 106
0 --> 1
Crossover_point mutation at index: 408
0 --> 1
Crossover_point mutation at index: 485
0 --> 1
Crossover_point mutation at index: 1180
0 --> 1
For each Base in InstructionSet, there is 2/20000 of the Base being mutated.
 There 2000 bases in an InstructionSet therefore the probability of no mutations taking place is (19998/20000)^2000.
 Thus in 100 calls to  mutate there should be  (1 - (19998/20000)^2000)*100 ~ 18.1277434734 mutations.
  The actual number of mutations: 16
#+end_example

* Thread And Organism Code
#+BEGIN_SRC python :noweb yes :tangle Organism.py
<<ThreadAndOrganism_Imports>>
<<Thread>>
<<Organism>>

#+END_SRC
** Imports
#+NAME: ThreadAndOrganism_Imports 
#+BEGIN_SRC python 
from BaseAndInstructionSet import *
from Decoder import Decoder
from PinAndPinGroup import *
import random
import os
import jsonpickle
#+END_SRC
** Class: Thread
*Input:* thread_decoder, a Decoder object\\
*Output:* a Thread, stores a section of an Organism’s InstructionSet and builds connections from it, whcih are also stored.\\
#+NAME: Thread
#+BEGIN_SRC python :noweb yes
class Thread:
    def __init__(self, thread_decoder):
        self.binary = []
        self.decoded_instructions = []
        self.connected_pins = []
        self.decoder = thread_decoder

    # simply calls the decoder to decode the thread's instructions
    def decode(self):
        self.decoded_instructions = self.decoder.generate_coords(self.binary)
#+END_SRC 
** Class: Organism
*Input:* generation, int,  the generation the org belongs to.\\
\indent generational index, int, tracks the order in which the orgs in a gen were created\\
\indent parent1=None, Organism, One of the orgs parents, defaults to None\\
\indent parent2=None, Organism, The other parent, also defaults to none\\
\indent genome=None: An InstructionSet, defaults to None.\\
*Output:* An Organism object. It keeps track of an individual’s genome, lineage, and experimental performance, as well as builds its phenotype from the genome.\\

#+NAME: Organism
#+BEGIN_SRC python :noweb yes 
  class Organism:
      def __init__(self, generation, generational_index,genome_size, num_crossover_points, unrestricted_crossover_point_distribution, thread_length, parent1=None, parent2=None, genome=None):
          # store perfromance on behavioral task
          self.performance_1 = None
          self.performance_2 = None
          self.reproduction_possibilities = None
          self.generation = generation
          self.generational_index = generational_index
          # store organizational and naming information
          #NOTE: no longer saves a reference to parent org object
          #as that resulted in gigundus file sizes
          #try-except block necessary because parents may be None
          try:
              self.parent1_generation = parent1.generation
              self.parent1_generational_index = parent1.generational_index
              self.parent2_generation = parent2.generation
              self.parent2_generational_index = parent2.generational_index
          except AttributeError:
              pass
          self.filename = self.set_file_name()
          thread_length = thread_length
          self.instruction_set = InstructionSet(genome_size, num_crossover_points,unrestricted_crossover_point_distribution, thread_length)
          #This conditional is recquired for threads to build with
          # recombinated genome
          if genome is None: self.genome = self.instruction_set.genome
          else: self.genome = genome
          self.decoder = Decoder()
          # initialize pin groups
          self.group1 = Group1()
          self.group2 = Group2()
          self.group3 = Group3()
          self.group4 = Group4()
          self.group5 = Group5()
          self.group6 = Group6()
          self.groupPl = GroupPl()
          self.groupRl = GroupRl()
          self.groupRr = GroupRr()
          self.groupPr = GroupPr()
          self.groupBl = GroupBl()
          self.groupBr = GroupBr()
          self.groupFl = GroupFl()
          self.groupFr = GroupFr()
          # organize pin groups into a single list
          self.pinGroups = [self.group1, self.group2, self.group3, self.group4, self.group5, self.group6, self.groupPl,
                            self.groupRl, self.groupRr, self.groupPr, self.groupBl, self.groupBr, self.groupFl, self.groupFr]
          # threads will eventually be created and appended to the thread list
          self.threads = []
          # store the pins currently connected in the organism (in no specific order)
          self.connections = []

          self.create_threads(thread_length)
          self.generate_thread_instructions()
          self.build_thread_coordinates()
      <<Class Methods>>

  <<Other Methods>>
#+END_SRC

*** Class Methods

#+NAME: Class Methods
#+BEGIN_SRC python :noweb yes
<<set_file_name>>
<<save_to_file>>
<<create_threads>>
<<generate_thread_instructions>>
<<build_thread_coordinates>>
<<is_viable>>
#+END_SRC
**** set file name
*Input:*  None\\
*Output:* A unique string for identifying a particular organism, containing generational info as well as the name of the Organism’s parents.\\
#+NAME: set_file_name
#+BEGIN_SRC python 
    """
    creates the string for the organism's filename
    """
    def set_file_name(self):
        #if self.parent1 is not None and self.parent2 is not None:
        try:
            filename = (str(self.generation) + "_" +
                        str(self.generational_index) + "_" +
                        str(self.parent1_generation) + "_" +
                        str(self.parent1_generational_index) + "_" +
                        str(self.parent2_generation) + "_" +
                        str(self.parent2_generational_index))
        except AttributeError:
            filename = (str(self.generation) + "_" +
                        str(self.generational_index) + "_" +
                        str(" ") + "_" +
                        str(" ") + "_" +
                        str(" ") + "_" +
                        str(" "))
        return filename

#+END_SRC
**** save to file
*Input:* path: full path to desired location\\
*Output:* a new directory named after the Organism, containing a pickled instantiation of the Organism. \\
#+NAME: save_to_file
#+BEGIN_SRC python 
    def save_to_file(self, path):
        dir = os.mkdir(path+"/"+self.filename)
        with open(path+"/"+self.filename+"/"+self.filename+".txt", 'wb') as output:
            data = jsonpickle.encode(self)
            output.write(data)
#+END_SRC
**** create threads
#+NAME: create_threads
#+BEGIN_SRC python 
    def create_threads(self, thread_length):
        for genome_index in range(0, len(self.genome), thread_length):
            # iteratively create lists of base chars of size 'thread_length'
            # these lists will become the binary for the threads
            new_thread = Thread(self.decoder)
            try:
                # get the chars from each base in the segment of the instruction code being examined
                thread_binary = ([self.genome[i].char for i in range(genome_index,  genome_index+thread_length)])
                new_thread.binary = thread_binary
                self.threads.append(new_thread)
            # in the event of not having enough bases to create an entire thread
            # let the thread be truncated, and stop copying over bases, and append it to the list of threads
            except IndexError:
                thread_binary = ([self.genome[i].char for i in range(genome_index, len(self.genome))])
                new_thread.binary = thread_binary
                self.threads.append(new_thread)
#+END_SRC
**** generate thread instructions
*Input:* Nothing\\
*Output:* Nothing\\
*Side Effect:* The binary instructions for each Thread in self.threads (see above) is decoded into corresponding coordinate instructions (see Decoder).\\
#+NAME: generate_thread_instructions
#+BEGIN_SRC python
    def generate_thread_instructions(self):
        for thread in self.threads:
            # instructions are xy coordinate points to plug into the pinGroups
            thread.decode()
            #print thread.decoded_instructions

#+END_SRC 
**** build thread coordinates
*Input:* Nothing\\
*Output:* Nothing\\
*Side Effect:* Determines the pins connected as dictated by the coordinates of each thread.\\
*Process:* Each Thread is ‘built’ (i.e.  their decoded_instructions are used to accesses PinGroups and Pins (see below))
 using a round-robin approach. This done by simultaneously building each thread, one index at a
 time. Threads that are actively being built are stored in the list active_threads. Threads are
 removed from active_threads if they collided with with a previously built Thread, for trying 
to accesses out of bounds Pins, for having only one valid pin, etc. Pins are accessed using the
 xyz coordinates stored in Thread.decoded_instructions, where x corresponds to the PinGroup, y
 corresponds to a specific Pin in the PinGroup, and z corresponding to another Pin within that
 same PinGroup-- the origin of the next wire. After each Thread is built, and therefore 
active_threads is empty, threads are checked to make sure there are no connections without a
 terminal pin. \\
#+NAME: build_thread_coordinates
#+BEGIN_SRC python
    def build_thread_coordinates(self):
        # threads will be temporarily copied into a separate list of running threads, to determine when the process of
        # making their connections is completed
        running_threads = []
        for thread in self.threads:
            # we only want to use the the threads that connect at least two pins.
            # this is represented by the number of instructions in said thread
            if len(thread.decoded_instructions) >= 2:
                running_threads.append(thread)

        # using a round-robin approach attempt to pair a thread's coordinate to a pin. when the thread fails for
        # some reason (i.e. collision between threads, or coordinates not corresponding to an available pin)
        # the thread will not be runnable and be taken from the running_threads list
        index = 0
        #tracks which threads have been run, and in turn, when the index should be incremented
        num_threads_run = 0
        active_threads = [i for i in running_threads] #A deepcopy that we are free to modify
        while len(active_threads) > 0:
            #print '\nThread index: %s' % index
            for running in running_threads:
                # check the next index in all of running thread when all threads have been run on the previous index
                if num_threads_run % len(running_threads):#len(running_threads):
                    index += 1
                    #print "---------------------------------------------\nNew Index:  %s" % index
                    num_threads_run = 0

                error_encountered = False
                # declare variables for finding and storing a selected pin
                if running in active_threads:
                    #print '\nActive Thread Coords:', running.decoded_instructions
                    try:
                        # get the specific pin coordinates from the instruction and translate it to make it a valid pin
                        pin_coordinates = running.decoded_instructions[index]
                        accessed_pin_group = self.pinGroups[pin_coordinates[0]]
                        accessed_output_pin = accessed_pin_group.get_input(pin_coordinates[1])
                        #print "Coords: %s  Group : %s  Pin: %s" % (pin_coordinates, accessed_output_pin.group_id,accessed_output_pin.number)
                        # Jake addition 2015-06-09 this hopefully chooses another pin to be the origin 
                        # ofrthe next connection (same pin group as terminus of previous connection)
                    # print pin_coordinates,

                    # an index error means that the thread's coordinates could not connect to an actual pin
                    except IndexError:
                        try:
                            #print "Out of Bounds coordinate: %s. Thread deactivated" %  str(running.decoded_instructions[index])
                            pass
                        except IndexError:
                            pass
                        #print 'Bad index: %s' % index
                        error_encountered = True
                        # if a thread only has one pin, then it cannot create a connection, and the pin must be made available
                        if len(running.connected_pins) == 1:
                            to_remove = running.connected_pins[0]
                            # set the pin's availability to 'true'
                            to_remove.available = True
                            # remove the pin from the thread's & organism's group of connected pins
                            for x in range(len(self.connections)):
                                if (self.connections[x].group_id == to_remove.group_id and
                                            self.connections[x].number == to_remove.number):
                                    del self.connections[x]
                                    break
                            # wipe the running thread's connected pins since it only contains one pin, which cannot connect
                            running.connected_pins = []
                        active_threads.remove(running)

                # it is possible that the pin exists but has been taken
                    if not error_encountered:
                        try:
                            # ensure the pin hasn't been 'taken' by another thread already
                            if accessed_output_pin in self.connections:
                                #print "pin already taken: %s" % accessed_output_pin.group_id
                                raise LookupError("Connection failed: pin already connected")
                            ###WARNING: OUTDATED CODE
                            # its possible the accessed pin is unavailable, signifying it was already taken by another thread
                            #if not accessed_pin.available:
                            #    raise LookupError("Connection failed: pin already connected")
                            else:
                                self.connections.append(accessed_output_pin)
                                running.connected_pins.append(accessed_output_pin)

                            #print 'connected pins:',[i.group_id for i in running.connected_pins]
                            if len(pin_coordinates) == 3: #and (len(running.decoded_instructions) % 2) != 0:
                                new_connection_origin = accessed_pin_group.get_output(pin_coordinates[2])
                            else:
                                new_connection_origin = None
                                # ensure the pin hasn't been 'taken' by another thread already
                                # connect to a random input pin in the same group
                                # input pins are used since the previous pin was an output
                                #output_pin = accessed_pin_group.get_random_input()
                                #self.connections.append(output_pin)
                                #running.connected_pins.append(output_pin)
                            if new_connection_origin is not None:
                                if new_connection_origin in self.connections:
                                    raise LookupError("Connection failed: pinalready connected!")
                                else:
                                    self.connections.append(new_connection_origin)
                                    running.connected_pins.append(new_connection_origin)

                        except LookupError:
                            # if a thread only has two pins, then it cannot create a connection to pins outside of the initial
                            # group, and each pin must be made available
                            if len(running.connected_pins) == 2:
                                error_encountered = True
                                for x in range(len(running.connected_pins)):
                                    # set the pin's availability to 'true'
                                    running.connected_pins[x].available = True
                                    # remove the pin from the thread's & organism's group of connected pins
                                    #self.connections.remove(running.connected_pins[x])
                                    for n in range(len(self.connections)):
                                        if (self.connections[n].group_id == running.connected_pins[x].group_id and
                                            self.connections[n].number == running.connected_pins[x].number):
                                            del self.connections[n]
                                            break

                                # wipe the running thread's connected pins since it only contains two pins,
                                # which is not a complete connection
                                running.connected_pins = []
                            active_threads.remove(running)
                            if len(running.connected_pins) >  2:
                                    pass
            num_threads_run += 1

        for running in self.threads:             
            if len(running.connected_pins) % 2 != 0:# and \
                    #len(running.connected_pins) >= 1:
                x =len(running.connected_pins)- 1
                to_remove =  running.connected_pins[-1]
                to_remove.available = True
                running.connected_pins.remove(to_remove)
                #running.connected_pins[len(running.connected_pins) - 1].available = True
                connections_copy = [n for n in self.connections] #deepcopy that we can manipulate
                                                                #with impunity
                for n in self.connections:
                    if (n.group_id == to_remove.group_id and\
                        n.number == to_remove.number):
                        connections_copy.remove(n)
                self.connections = connections_copy
                #running.connected_pins = [running.connected_pins[i] for i in range(x - 1)]
                #print 'thread stuff \n' +  [i.group_id for i in running.connected_pins]
            else:
                #for running in running_threads:
                pass

#+END_SRC
**** is viable
*Input:* Nothing\\
*Output:* Boolean depending on whether there is a sensorimotor connection 
present in an Organism’s phenotype.
*Process:* instantiates  s ^ m ∈ C, where s ∈ sensory PinGroup, m ∈ motor PinGroup and C is 
the set of all connected pins in a given thread.\\

#+NAME: is_viable
#+BEGIN_SRC python :noweb yes
  def is_viable(self):
      connected_pins = []

      def check1():
          for connected_pin_group in connected_pins:
              if (#("bl" in connected_pin_group and "fr" in connected_pin_group) or
                     # ("fl" in connected_pin_group and "br" in connected_pin_group) or
                      ("bl" in connected_pin_group and "br" in connected_pin_group ) or
                      ("fl" in connected_pin_group and "fr" in connected_pin_group)):
                  return True
          return False

      def check3():
          for connected_pin_group in connected_pins:
              if ((#"rr" in connected_pin_group or
                           #"rl" in connected_pin_group or
                           "pl" in connected_pin_group or
                           "pr" in connected_pin_group) and
                      ("fl" in connected_pin_group or
                               "bl" in connected_pin_group or
                               "fr" in connected_pin_group or
                               "br" in connected_pin_group)):

                  return True
              return False

      def check4():
          try:
               if connected_pins[0] ==connected_pins[1] and connected_pins\
                  [len(connected_pins) - 1]\
                        ==  connected_pins[len(connected_pins) - 2]: 
                      False
               else:
                      True
          except(IndexError):
              pass

      for t in self.threads:
          if len(t.connected_pins) > 0:
              # make a set out of the connected pins of the thread
              t_set = set([pin.group_id for pin in t.connected_pins])
              connected_pins.append(t_set)
              # loop through the list, and for every group of connected pins, check the \
                  #intersection of it &
              # and its neighbor.
              # If there is an intersection, place the union of the two sets in the connected_pin
              # group and remove the two original sets. This will determine if the correct pins are wired
              # to create a viable phenotype
              for x in range(len(connected_pins)-1):
                  if len(set(connected_pins[x]).intersection(set(connected_pins[x+1]))) > 0:
                      merged_set = set(connected_pins[x]).union(connected_pins[x+1])
                      connected_pins.remove(connected_pins[x+1])
                      connected_pins.remove(connected_pins[x])
                      connected_pins.append(merged_set)
                      # check to see if the length of the connected_pin set has changed due\
                          #to appends and removes
                      if x < len(connected_pins)-1:
                          break


      if check1() and check3( ):  # and check2():
          #print "connected pins: ", connected_pins
          return True
      else:
          return False




#+END_SRC
*** Other Methods
#+NAME: Other Methods
#+BEGIN_SRC python :noewb yes
<<reproduce>>
<<generate_viable>>

#+END_SRC
**** Method: reproduce
*Input:* org1: an Organism\\
org2: an Organism\\
path: path to the directory where the offspring will be saved.
*Output:* An Organism with a recombinant  genome from org1 and org2’s genetic material, and 
saved (via pickle) in a directory located at path.\\ 
*Process:* A parent is chosen at random to be the ‘dominant’ and ‘recessive’ parent. 
The algorithm first starts copying the Bases from the dominant’s InstructionSet to child1_genome.
 When it reaches a Base with a crossover_point value equal to 1, it begins copying Bases starting 
from the successive locus in recessive parent’s InstructionSet. This switch will occur every time a
 crossover_point value of 1 is encountered. A new Organism is then instantiated with the resultant
 recombinant genome, and is saved to a new directory (bearing its name) located at path.\\

#+NAME: reproduce
#+BEGIN_SRC python
  def reproduce(org1, org2, path):
      dom = random.choice([org1, org2])  # Parent whose crossover points are being used
      rec = filter(lambda y: y != dom, [org1, org2])
      rec = rec[0]# Other parent
      child1_genome = []
      gen_count = 0
      index = 0
      # This is how the offsprings genome is made
      #allows for crossing over at nonhotspots at 1/100000 chance.
      """"while index < len(dom.genome):
          child1_genome.append(dom.genome[index])
          if dom.genome[index].crossover_point == 1:
              while dom.genome[index + 1].crossover_point != 1 and \
                      index + 1 < len(dom.genome) - 1:
                          child1_genome.append(rec.genome[index + 1])
                          index += 1
          index += 1"""

      dom_genome_copy = True
      dom_stuff =[]
      rec_stuff=[]
      while index <= len(dom.genome) - 1:
          """if index  % 4 == 0:
              dom_stuff.append('')
              #rec_stuff.append('|')"""
          if dom_genome_copy:
              child1_genome.append(dom.genome[index])
              dom_stuff.append(dom.genome[index].char)
              rec_stuff.append(rec.genome[index].char)
              if dom.genome[index].crossover_point == 1:
                  dom_stuff.append('HERE')
                  rec_stuff.append('HERE')
                  dom_genome_copy = False
              index += 1
          else:
              child1_genome.append(rec.genome[index])
              dom_stuff.append(rec.genome[index].char)
              rec_stuff.append(rec.genome[index].char)
              if rec.genome[index].crossover_point == 1:
                  dom_stuff.append('HERE')
                  rec_stuff.append('HERE')
                  dom_genome_copy = True
              index +=1
      """"for i in range (0, len(dom_stuff)- 1):
          print '%s  %s' %  (dom_stuff[i], rec_stuff[i])
      print dom_stuff"""


      # This takes care of  of saving the Org.
      # if the path specified does not exist a new directory
      # will be created

      count = 0
      if os.path.isdir(path):
          for root, dirs, files in os.walk(path, topdown=False):
              for name in files:
                  count += 1
          child_instruction_set = InstructionSet(2100, 2,True,300)
          child_instruction_set.setGenome(child1_genome)
          child_instruction_set.mutate()
          child1 = Organism(dom.generation + 1, count,2100,2,True,300, dom, rec, child_instruction_set.genome)
      else:
          os.makedirs(path)
          child_instruction_set = InstructionSet(2100, 2,True,300)
          child_instruction_set.setGenome(child1_genome)
          child_instruction_set.mutate()
          child1 = Organism(dom.generation + 1, 0,2100,2,True,300, dom, rec, child_instruction_set.genome)
          #print [i.char for i in child1.genome]
     # print 'child %s threads:' % child1.filename
     # for thread in child1.threads:
     #     print thread.decoded_instructions
     #     print [i.group_id for i in thread.connected_pins]
      child1.save_to_file(path)
     # print 'Dom  Rec  Crossover  real_offspring'
     # for i in range(len(child1_genome) - 1):
     #     print '%s      %s      %s          %s' % (dom.genome[i].char, rec.genome[i].char, child1_genome[i].crossover_point,child1_genome[i].char)
      #if is_same_genome(dom, child1): print 'THEYRE SAME'
      #else: print 'THYRE DIFF'
      return child1
#+END_SRC
**** Method: generate viable
Generates a viable organism 
#+NAME: generate_viable
#+BEGIN_SRC python
def generate_viable():
    # writes a 'progress bar' to the console
    def progress(x):
        out = '\r %s organisms tested' % x  # The output
        print out,

    genomes_tested = 0
    finished = False
    while not finished:
        test = Organism(0, 0)
        if test.is_viable():
            print "-------------------------------------//"
            print "connections: "
            for thread in test.threads:
                print "new thread connections:"
                for connection in thread.connected_pins:
                    print connection.group_id, connection.number
            print "-------------------------------------//"
            finished = True
        else:
            del test
            genomes_tested += 1
            progress(genomes_tested)
#+END_SRC
* HoboSensor Analysis
#+BEGIN_SRC python :tangle HoboAnalysis.py
import csv
from collections import defaultdict
def energyAcquired(*args):
    columns = defaultdict(list)
    result = []
    for arg in args:
        with open(arg) as f:
            reader = csv.reader(f)
            reader.next()
            for row in reader:
                for (i,v) in enumerate(row):
                    try:
                        columns[i].append(v)
                    except ValueError:
                        pass
            for i in filter(lambda x: len(x) < 4, columns[2]):
                result.append(float(i))
            return sum(result)
#+END_SRC
* Crossing Algorithms
** RankAndCrossGeneration
#+BEGIN_SRC python :noweb yes :tangle RankAndCrossGeneration.py
<<RankAndCrossImports>>
<<json_load_file>>
<<calculateStdError>>
<<thresholdedCrossGeneration>>

#+END_SRC
*** Imports
#+NAME:RankAndCrossImports
#+BEGIN_SRC python
__author__ = 'JakeBrawer'
#from json_load_file import json_load_file
import json
import jsonpickle
import random
from  Organism import *
import HoboAnalysis
import os
import math
import datetime
import csv
import gc
global_quartiles = {}
#+END_SRC

*** Method: json_load_file
Reads in a jsonpickle file (a txt file) and turns it back into the proper object.
#+NAME:json_load_file
#+BEGIN_SRC python 
def json_load_file(filename):
    f = open(filename)
    json_str = f.read()
    obj = jsonpickle.decode(json_str)
    return obj

#+END_SRC
*** Method:calculateStdError 
*INPUT:* list_of_vals-- list containing values of interest
         average-- The average of the list of vals
This outputs the standard error of the list of vals, which will then be stored in a csv 
along with other statistical info. Useful for result analysis later on.
#+NAME: calculateStdError
#+BEGIN_SRC python
def calculateStdError(list_of_vals, average):
    stddev = 0.0
    diffsquared = 0.0
    sum_diffsquared = 0.0
    print '\n--------------------------------------------------\nCalculating the Std Error of the mean: '
    for val in list_of_vals:
        diffsquared = (val- average)**2.0
        sum_diffsquared += diffsquared 
        print 'Org mean perf: %s Pop mean: %s Diffsqrd: %s SumDiffsqrd: %s ' % (val, average, diffsquared, sum_diffsquared)
    stddev = ((sum_diffsquared)/len(list_of_vals))**(1.0/2.0)
    stderror = stddev / (len(list_of_vals)**(1.0/2.0))
    print 'Stddv: %s  StdErr: %s\n------------------------------------------------------------\n ' % (stddev, stderror)
    #print(numpy.sqrt(numpy.var(list_of_vals)))
    return stderror
#+END_SRC
*** Method: thresholdedCrossGeneration
#INPUT: experiment_directory -- direcotry containing all the gens for the given experiment
     #gen_directory -- directory containing subdirectories of agents in a given generation
     #  path_to_new_generation -- where you want the direcotry containing new dir
     #  *new_gen_size --(OPTIONAL) upperlimit on number of individuals in new generation
#OUTPUT: A direcory containing individuals from the next generation
#+NAME: thresholdedCrossGeneration
#+BEGIN_SRC python :noweb yes 
  def thresholdedCrossGeneration(experiment_directory, gen_directory,path_to_new_gen,*new_gen_size):
      unpickled_orgs = []# temporarily holds unpickled orgs
      try:
          new_gen_size = int( new_gen_size[0]) #turns the input (a tuple) into an int
      except IndexError:
          new_gen_size = None #No size input given
      <<evaluateGenerationPerformance>>
      <<calculateRankings>>
      <<crossAndSaveGeneration>>
      <<writeQuartilesToCSV>>

      crossAndSaveGeneration(path_to_new_gen, new_gen_size)
      #calculateRankings(gen_directory)
      writeQuartilesToCsv(global_quartiles, experiment_directory)
#+END_SRC
*** SubMethod: evaluateGenerationPerformance
#INPUT: Directory containing gen to be crossed
#OUTPUT: Calculates performance thresholds based on the mean pop. performance
        #orgs < Q1 dont reproduce, Q1<= org < Q2 can reproduce once, Q2 <= org <Q3
        #twice, etc.
#+NAME: evaluateGenerationPeformance
#+BEGIN_SRC python 
    def evaluateGenerationPerformance(gen_directory):
        global global_quartiles
        mean_performance_per_org = [] 
        mean_performance_per_pop = 0
        list_of_vals = []
        y = []
        #walks through files belonging to an organism, one org at a time
        print "All the org files in this directory:"
        for root, dir, files in os.walk(gen_directory):
            org = None
            #will store the amount of light collected on both trials
            performance_1 = 0
            performance_2 = 0
            y.append(root)
            for f in files:
                try:
                    y.append(f)
                    if f.endswith('.pkl') or f.endswith('.txt'):
                        org = json_load_file(root + '/' + f,'rb')
                        print  rooty + '/'+ f
                        #print [i.crossover_point for i in org.genome]
                    elif f.endswith('.csv'):
                        if f == 'quartile_data.csv':
                            pass
                        else:
                            if performance_1 == 0:
                                #rooty denotes the path to subdir, f a file in root. Concatenating
                                # the two results in the full path to file
                                performance_1 = HoboAnalysis.energyAcquired(rooty +'/' + f) 
                            else:
                                performance_2 = HoboAnalysis.energyAcquired(rooty + '/' + f)
                except AttributeError:
                    pass
            try:
                org.performance_1 = performance_1
                org.performance_2 = performance_2
                #append the average of two performances to list
                #for use later in calculating stddev
                mean_performance_per_org.append((org.performance_1 + org.performance_2)/2)
                unpickled_orgs.append(org)
                # org.save_to_file(f)
            except AttributeError:
                pass
    #for org in unpickled_orgs:
        #   mean_performance_per_org.append((org.performance_1 + org.performance_2) / 2.0 )"""
        print'\n mean performances for each org in population:', mean_performance_per_org
        #Calculates quartiles: Q1 = mean * .5, Q2 = mean, Q3 = mean * 1.5
        mean_performance_per_pop = sum(mean_performance_per_org)/len(mean_performance_per_org)
        #Saves quartile information and stdev of pop mean to a dict
        quartiles = {'Generation': unpickled_orgs[0].generation, 'mean': mean_performance_per_pop, 'stderr': calculateStdError(mean_performance_per_org, mean_performance_per_pop)}
        print '\nquartiles: %s\n' % quartiles  
        global_quartiles = quartiles
        return quartiles
#+END_SRC
*** SubMethod: calculateRankings

#INPUT: dir containing gen of interest
#OUTPUT: Sorts organisms into lists that denote how many offspring they
        #can potentially create
#+NAME: calculateRankings
#+BEGIN_SRC python
    def calculateRankings(gen_directory):
        evaluateGenerationPerformance(gen_directory)
        sorted_orgs = sorted(unpickled_orgs, key=lambda x: (x.performance_1 + x.performance_2)/2.0,\
                             reverse=True)
        ranking = []
        while len(sorted_orgs) >0:
            ranking.append([sorted_orgs.pop(0), sorted_orgs.pop(0)])

        print 'ranking:', ranking

        return ranking
   
#+END_SRC
*** SubMethod: crossAndSaveGeneration
#INPUT: path_to_new_gen: where to save the new gen data
    #   new_gen_size: the upperlimit (if any) to the new gen
#OUTPUT: New generation of orgs saved to path_to_new_gen 
#+NAME: crossAndSaveGeneration
#+BEGIN_SRC python :noweb yes
    def crossAndSaveGeneration(path_to_new_gen,new_gen_size):
        #These lines calculate the quartiles, and then save each area 
        #above a quartile to its own list
        rankings = calculateRankings(gen_directory)
        fours = rankings.pop(0)
        threes = rankings.pop(0)
        twos = rankings.pop(0)
        ones = rankings.pop(0)
        <<chooseTwoToCross>>
#+END_SRC
**** SubMethod: chooseTwoToCross
#INPUT: path_to_new_gen -- see above
#OUTPUT: Crosses to orgs (if any are present in the above lists) 
# and sve their offspring to a direcotry located in path_to_new_gen
#+NAME: chooseTwoToCross
#+BEGIN_SRC python
  def chooseTwoToCross(path_to_new_gen):
      org1 = None
      org2 = None
      #This horribly ugly blcok of code handles the selection of the orgs
      #To be crossed. The algorithm always looks two cross orgs in the higher
      #lists first (i.e. threes then twos then ones). Once an organism has been
      #crossed, they are put into a lower list (Threes-->twos, etc), or are
      #removed altogether from the lists (ones --> n/a)
      try:
          print 'fours %s' % [i.filename for i in fours]
          print 'threes %s' % [i.filename for i in threes]
          print 'twos %s' % [i.filename for i in twos]
          print 'ones %s' % [i.filename for i in ones]
      except IndexError:
          pass
      if len(fours) > 0:
          org1 = random.choice(fours)
          fours.remove(org1)
          threes.append(org1)
      elif len(threes) > 0:
          org1 = random.choice(threes)
          threes.remove(org1)
          twos.append(org1)
      elif len(twos) > 0:
          org1 = random.choice(twos)
          ones.append(org1)
          twos.remove(org1)
      elif len(ones) > 0:
          org1 = random.choice(ones)
          ones.remove(org1)
      if len(fours) > 0:
          fours_sans_org1 = filter(lambda y:y != org1, fours)
          org2 = random.choice(fours_sans_org1)
          fours.remove(org2)
          threes.append(org2)
      elif len(threes) > 0:
          try:
              threes_sans_org1 = filter(lambda y:y != org1, threes)
              org2 = random.choice(threes_sans_org1)
              threes.remove(org2)
              twos.append(org2)
          except IndexError:
              pass
      elif len(filter(lambda y:y != org1, twos)) > 0:
          try:
              twos_sans_org1 = filter(lambda y:y != org1, twos)
              org2 = random.choice(twos_sans_org1)
              ones.append(org2)
              twos.remove(org2)
          except IndexError:
              pass
      elif len(filter(lambda y:y != org1, ones)) > 0:
          try:
              ones_sans_org1 = filter(lambda y:y != org1, ones)
              org2 = random.choice(ones_sans_org1)
              ones.remove(org2)
          except IndexError:
              pass
              #print 'one filtered list %s' % ones_sans_org1
      print 'org1 %s, org2 %s' % (org1.filename, org2.filename)
      if org1 is not None and  org2 is not None:
          print 'crossing org1:%s with org2:%s\n' % (org1.filename, org2.filename, 
                                                             )
          reproduce(org1, org2, path_to_new_gen)
          return True
      else:
          return False
  #This block handles how much crossing is actually done. If an upper limit
  # is specified via a non None new_gen_size val, crossing will stop after
  #those many offspring have been created. Otherwise orgs will be crossed as
  #long as there are orgs in any of the lists.
  print '------------------------------------------------------------\nCrossing Generation:\n'
  if new_gen_size is not None:
      while(new_gen_size > 0):
          reproduction = chooseTwoToCross(path_to_new_gen)
          if reproduction is True:
              new_gen_size -= 1
          else:
              break
  else:
      count = 0
      while ( len(threes) + len(twos) +len(ones)) >= 2:
          chooseTwoToCross(path_to_new_gen)
          count += 1
      print '\nNumber of Orgs in new gen: %s' % count
#+END_SRC
*** SubMethod: wrtieQuartilesToCsv
#+NAME: writeQuartilesToCsv
#+BEGIN_SRC python
    def writeQuartilesToCsv(data_dict, dir):
        #os.mkdir(dir)
        data_file =  dir + '/' + 'experiment_data.csv' 
        if os.path.isfile(data_file):
            with open(dir + '/' + 'experiment_data.csv' , 'a') as f:
                fieldnames = ['Generation', 'mean', 'stderr']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writerow(data_dict)
        else:
            with open(dir + '/' + 'experiment_data.csv' , 'wb') as f:
                fieldnames = ['Generation', 'mean', 'stderr']
                writer = csv.DictWriter(f, fieldnames=fieldnames)

                writer.writeheader()
                writer.writerow(data_dict)
#+END_SRC
 
** RankAndCrossByThreadCount
Pretty much the same as [[RankAndCrossGeneration]] except it selects for the number of active threads and NOT for perfromance.
*Used for simulations*
#+NAME: RankAndCrossByThreadCount
#+BEGIN_SRC python

__author__ = 'JakeBrawer'
from json_load_file import json_load_file
import random
import Organism
import HoboAnalysis
import os
import math
import datetime
import csv
import gc
global_quartiles = {}

#INPUT: list_of_vals-- list cont
def calculateStdError(list_of_vals, average):
    stddev = 0.0
    diffsquared = 0.0
    sum_diffsquared = 0.0
    print '\n--------------------------------------------------\nCalculating the Std Error of the mean: '
    for val in list_of_vals:
        diffsquared = (val- average)**2.0
        sum_diffsquared += diffsquared 
        print 'Org mean perf: %s Pop mean: %s Diffsqrd: %s SumDiffsqrd: %s ' % (val, average, diffsquared, sum_diffsquared)
    stddev = ((sum_diffsquared)/len(list_of_vals))**(1.0/2.0)
    stderror = stddev / (len(list_of_vals)**(1.0/2.0))
    print 'Stddv: %s  StdErr: %s\n------------------------------------------------------------\n ' % (stddev, stderror)
    #print(numpy.sqrt(numpy.var(list_of_vals)))
    return stderror

#INPUT: experiment_directory -- direcotry containing all the gens for the given experiment
     #gen_directory -- directory containing subdirectories of agents in a given generation
     #  path_to_new_generation -- where you want the direcotry containing new dir
     #  *new_gen_size --(OPTIONAL) upperlimit on number of individuals in new generation
#OUTPUT: A direcory containing individuals from the next generation
def thresholdedCrossGeneration(experiment_directory, gen_directory,path_to_new_gen,*new_gen_size):
    unpickled_orgs = []# temporarily holds unpickled orgs
    try:
        new_gen_size = int( new_gen_size[0]) #turns the input (a tuple) into an int
    except IndexError:
        new_gen_size = None #No size input given

    #INPUT: Directory containing gen to be crossed
    #OUTPUT: Calculates performance thresholds based on the mean pop. performance
            #orgs < Q1 dont reproduce, Q1<= org < Q2 can reproduce once, Q2 <= org <Q3
            # twice, etc.
    def evaluateGenerationPerformance(gen_directory):
        global global_quartiles
        num_threads_per_org = [] 
        mean_threads_per_pop = 0
        list_of_vals = []
        y = []
        #walks through files belonging to an organism, one org at a time
        print 'Active Threads per org:\n'
        for root, dir, files in os.walk(gen_directory):
            for f in files:
                print 'File',
                try:
                    y.append(f)
                    if f.endswith('.pkl') or f.endswith('.txt'):
                        org = json_load_file(root + '/' + f)
                        #print  root + '/'+ f
                        print org.filename
                        # This stores the number of active threads per org in org.performance_1,
                        # which is used to rank the organism later on.
                        thread_count = 0
                        for thread in org.threads:
                            print 'thread len.:',len(thread.connected_pins)
                            if len(thread.connected_pins) > 0:
                                thread_count += 1
                        org.performance_1 = thread_count
                        print '\nthread count', thread_count
                        print
                        num_threads_per_org.append(org.performance_1)
                except AttributeError:
                    print 'Error'
                    pass
                try:
                    unpickled_orgs.append(org)
                except AttributeError:
                    print 'append error'
                    pass
        print'\n mean performances for each org in population:', num_threads_per_org
        try:
            mean_threads_per_pop = sum(num_threads_per_org)/float(len(num_threads_per_org)) #cast as a float to get float quotient
        except ZeroDivisionError:
            mean_threads_per_pop = 0 
        #Saves quartile information and stdev of pop mean to a dict
        quartiles = {'Generation': unpickled_orgs[0].generation, 'mean_threads': mean_threads_per_pop, \
                     'stderr': calculateStdError(num_threads_per_org, mean_threads_per_pop),\
                     'gen_size': len(unpickled_orgs), 'mode': max(set(num_threads_per_org), key=num_threads_per_org.count),\
                     'min': min(num_threads_per_org), 'max': max(num_threads_per_org)}
        print '\nquartiles: %s\n' % quartiles  
        global_quartiles = quartiles
        return quartiles

    #INPUT: dir containing gen of interest
    #OUTPUT: Sorts organisms into lists that denote how many offspring they
            # can potentially create
    def calculateRankings(gen_directory):
        evaluateGenerationPerformance(gen_directory)
        #Sorts orgs from Orgs with most threads to Orgs with least threads
        sorted_orgs = sorted(unpickled_orgs, key=lambda x: x.performance_1,\
                             reverse=True)
        ranking = []
        while len(sorted_orgs) >0:
            ranking.append([sorted_orgs.pop(0), sorted_orgs.pop(0)])

        for i in ranking:
            for r in i:
                print r.performance_1
        
        return ranking
   
    #INPUT: path_to_new_gen: where to save the new gen data
        #   new_gen_size: the upperlimit (if any) to the new gen
    #OUTPUT: New generation of orgs saved to path_to_new_gen 
    def crossAndSaveGeneration(path_to_new_gen,new_gen_size):
        #These lines calculate the quartiles, and then save each area 
        #above a quartile to its own list
        rankings = calculateRankings(gen_directory)
        fours = rankings.pop(0)
        threes = rankings.pop(0)
        twos = rankings.pop(0)
        ones = rankings.pop(0)
        #INPUT: path_to_new_gen -- see above
        #OUTPUT: Crosses to orgs (if any are present in the above lists) 
        # and sve their offspring to a direcotry located in path_to_new_gen
        def chooseTwoToCross(path_to_new_gen):
            org1 = None
            org2 = None
            #This horribly ugly blcok of code handles the selection of the orgs
            #To be crossed. The algorithm always looks two cross orgs in the higher
            #lists first (i.e. threes then twos then ones). Once an organism has been
            #crossed, they are put into a lower list (Threes-->twos, etc), or are
            #removed altogether from the lists (ones --> n/a)
            try:
                print 'fours %s' % [i.filename for i in fours]
                print 'threes %s' % [i.filename for i in threes]
                print 'twos %s' % [i.filename for i in twos]
                print 'ones %s' % [i.filename for i in ones]
            except IndexError:
                pass
            if len(fours) > 0:
                org1 = random.choice(fours)
                fours.remove(org1)
                threes.append(org1)
            elif len(threes) > 0:
                org1 = random.choice(threes)
                threes.remove(org1)
                twos.append(org1)
            elif len(twos) > 0:
                org1 = random.choice(twos)
                ones.append(org1)
                twos.remove(org1)
            elif len(ones) > 0:
                org1 = random.choice(ones)
                ones.remove(org1)
            if len(fours) > 0:
                fours_sans_org1 = filter(lambda y:y != org1, fours)
                org2 = random.choice(fours_sans_org1)
                fours.remove(org2)
                threes.append(org2)
            elif len(threes) > 0:
                try:
                    threes_sans_org1 = filter(lambda y:y != org1, threes)
                    org2 = random.choice(threes_sans_org1)
                    threes.remove(org2)
                    twos.append(org2)
                except IndexError:
                    pass
            elif len(filter(lambda y:y != org1, twos)) > 0:
                try:
                    twos_sans_org1 = filter(lambda y:y != org1, twos)
                    org2 = random.choice(twos_sans_org1)
                    ones.append(org2)
                    twos.remove(org2)
                except IndexError:
                    pass
            elif len(filter(lambda y:y != org1, ones)) > 0:
                try:
                    ones_sans_org1 = filter(lambda y:y != org1, ones)
                    org2 = random.choice(ones_sans_org1)
                    ones.remove(org2)
                except IndexError:
                    pass
                    #print 'one filtered list %s' % ones_sans_org1
            print 'org1 %s, org2 %s' % (org1.filename, org2.filename)
            if org1 is not None and  org2 is not None:
                print 'crossing org1:%s with org2:%s\n' % (org1.filename, org2.filename, 
                                                                   )
                Organism.reproduce(org1, org2, path_to_new_gen)
                return True
            else:
                return False
        #This block handles how much crossing is actually done. If an upper limit
        # is specified via a non None new_gen_size val, crossing will stop after
        #those many offspring have been created. Otherwise orgs will be crossed as
        #long as there are orgs in any of the lists.
        print '------------------------------------------------------------\nCrossing Generation:\n'
        if new_gen_size is not None:
            while(new_gen_size > 0):
                reproduction = chooseTwoToCross(path_to_new_gen)
                if reproduction is True:
                    new_gen_size -= 1
                else:
                    break
        else:
            count = 0
            while ( len(threes) + len(twos) +len(ones)) >= 2:
                chooseTwoToCross(path_to_new_gen)
                count += 1
            print '\nNumber of Orgs in new gen: %s' % count
   #INPUT: quartile_dict: the dict containing quartile info
         # dir: path_to_new_gen
   #OUTPUT: a CSV file saved to dir containing quartile data 
    def writeQuartilesToCsv(data_dict, dir):
        #os.mkdir(dir)
        data_file =  dir + '/' + 'experiment_data.csv' 
        if os.path.isfile(data_file):
            with open(dir + '/' + 'experiment_data.csv' , 'a') as f:
                fieldnames = ['Generation', 'mean_threads', 'stderr','gen_size', 'mode', 'min', 'max' ]
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writerow(data_dict)
        else:
            with open(dir + '/' + 'experiment_data.csv' , 'wb') as f:
                fieldnames = ['Generation', 'mean_threads', 'stderr','gen_size', 'mode', 'min', 'max' ]
                writer = csv.DictWriter(f, fieldnames=fieldnames)

                writer.writeheader()
                writer.writerow(data_dict)

            #w = csv.DictWriter(f, quartile_dict.keys())
            #w.writeheader()
            #w.writerow(quartile_dict)

    crossAndSaveGeneration(path_to_new_gen, new_gen_size)
    ##calculateRankings(gen_directory)
    writeQuartilesToCsv(global_quartiles, experiment_directory)
    gc.collect()


#thresholdedCrossGeneration('/home/jake/Dropbox/BraitenbotCode/Summer2015/2015-07-22- EvolvingThreadNumber/Selection_High_Mutation_Rate/Population_3', '/home/jake/Dropbox/BraitenbotCode/Summer2015/2015-07-22- EvolvingThreadNumber/Selection_High_Mutation_Rate/Population_3/Gen11' ,'/home/jake/Dropbox/BraitenbotCode/Summer2015/2015-07-22- EvolvingThreadNumber/Selection_High_Mutation_Rate/Population_3/Gen12' )



#+END_SRC
** Some tests in simulation 
#+BEGIN_SRC python :noweb yes :results output pp
  path = ""

  <<RankAndCrossByThreadCount>>
  def initial_gen(number_of_orgs, path):
      orgs = 0
      tested = 0
      while orgs < number_of_orgs:
          org = Organism.Organism(1, orgs,525,2,True,75)
          if org.is_viable():
              org.save_to_file(path)
              orgs += 1
              print "-------------------------------------//"
              print "connections: "
              for thread in org.threads:
                  print "new thread connections:"
                  for connection in thread.connected_pins:
                      print connection.group_id, connection.number
              print "-------------------------------------//"
          tested += 1
          #progress(tested)

  initial_gen(10, "/home/jake/Dropbox/BraitenbotCode/Summer2015/2015-07-22- EvolvingThreadNumber/Smaller_Introns_Populations/Default_1/Gen1")

  gen = 1
  while (gen < 11):
      path1 = "/home/jake/Dropbox/BraitenbotCode/Summer2015/2015-07-22- EvolvingThreadNumber/Smaller_Introns_Populations/Default_1/Gen"+str(gen)
      path2 = "/home/jake/Dropbox/BraitenbotCode/Summer2015/2015-07-22- EvolvingThreadNumber/Smaller_Introns_Populations/Default_1/Gen"+str(gen+1)
      thresholdedCrossGeneration("/home/jake/Dropbox/BraitenbotCode/Summer2015/2015-07-22- EvolvingThreadNumber/Smaller_Introns_Populations/Default_1", path1, path2)
      gen+=1
      
#+END_SRC

#+RESULTS:
#+begin_example
-------------------------------------//
connections: 
new thread connections:
new thread connections:
new thread connections:
new thread connections:
new thread connections:
new thread connections:
new thread connections:
pr 1
bl 2
bl 0
br 3
-------------------------------------//
-------------------------------------//
connections: 
new thread connections:
pl 5
bl 1
bl 3
br 0
new thread connections:
new thread connections:
new thread connections:
new thread connections:
new thread connections:
new thread connections:
-------------------------------------//
-------------------------------------//
connections: 
new thread connections:
new thread connections:
new thread connections:
rr 2
pr 1
pr 2
fr 1
fr 0
fl 2
new thread connections:
new thread connections:
i4 2
e4 0
new thread connections:
new thread connections:
-------------------------------------//
-------------------------------------//
connections: 
new thread connections:
new thread connections:
new thread connections:
new thread connections:
new thread connections:
pr 1
fr 1
fr 3
fl 1
new thread connections:
new thread connections:
-------------------------------------//
-------------------------------------//
connections: 
new thread connections:
new thread connections:
new thread connections:
new thread connections:
new thread connections:
new thread connections:
new thread connections:
pl 2
fl 2
fl 3
fr 2
-------------------------------------//
-------------------------------------//
connections: 
new thread connections:
new thread connections:
new thread connections:
pr 2
bl 3
bl 2
br 2
new thread connections:
new thread connections:
new thread connections:
new thread connections:
-------------------------------------//
-------------------------------------//
connections: 
new thread connections:
new thread connections:
new thread connections:
new thread connections:
pl 0
bl 0
bl 3
br 1
new thread connections:
new thread connections:
new thread connections:
-------------------------------------//
-------------------------------------//
connections: 
new thread connections:
new thread connections:
new thread connections:
new thread connections:
new thread connections:
pr 0
fl 0
fl 1
fr 1
new thread connections:
new thread connections:
-------------------------------------//
-------------------------------------//
connections: 
new thread connections:
new thread connections:
new thread connections:
pl 0
fr 0
fr 2
fl 1
new thread connections:
e2 0
e4 2
new thread connections:
new thread connections:
new thread connections:
-------------------------------------//
-------------------------------------//
connections: 
new thread connections:
new thread connections:
new thread connections:
new thread connections:
new thread connections:
new thread connections:
new thread connections:
pl 3
fl 3
fl 1
fr 3
-------------------------------------//
Active Threads per org:

File 1_7_ _ _ _ 
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 4
thread len.: 0
thread len.: 0

thread count 1

File 1_1_ _ _ _ 
thread len.: 4
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 0

thread count 1

File 1_6_ _ _ _ 
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 4
thread len.: 0
thread len.: 0
thread len.: 0

thread count 1

File 1_9_ _ _ _ 
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 4

thread count 1

File 1_4_ _ _ _ 
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 4

thread count 1

File 1_8_ _ _ _ 
thread len.: 0
thread len.: 0
thread len.: 4
thread len.: 2
thread len.: 0
thread len.: 0
thread len.: 0

thread count 2

File 1_5_ _ _ _ 
thread len.: 0
thread len.: 0
thread len.: 4
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 0

thread count 1

File 1_2_ _ _ _ 
thread len.: 0
thread len.: 0
thread len.: 6
thread len.: 0
thread len.: 2
thread len.: 0
thread len.: 0

thread count 2

File 1_3_ _ _ _ 
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 4
thread len.: 0
thread len.: 0

thread count 1

File 1_0_ _ _ _ 
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 0
thread len.: 4

thread count 1


 mean performances for each org in population: [1, 1, 1, 1, 1, 2, 1, 2, 1, 1]

--------------------------------------------------
Calculating the Std Error of the mean: 
Org mean perf: 1 Pop mean: 1.2 Diffsqrd: 0.04 SumDiffsqrd: 0.04 
Org mean perf: 1 Pop mean: 1.2 Diffsqrd: 0.04 SumDiffsqrd: 0.08 
Org mean perf: 1 Pop mean: 1.2 Diffsqrd: 0.04 SumDiffsqrd: 0.12 
Org mean perf: 1 Pop mean: 1.2 Diffsqrd: 0.04 SumDiffsqrd: 0.16 
Org mean perf: 1 Pop mean: 1.2 Diffsqrd: 0.04 SumDiffsqrd: 0.2 
Org mean perf: 2 Pop mean: 1.2 Diffsqrd: 0.64 SumDiffsqrd: 0.84 
Org mean perf: 1 Pop mean: 1.2 Diffsqrd: 0.04 SumDiffsqrd: 0.88 
Org mean perf: 2 Pop mean: 1.2 Diffsqrd: 0.64 SumDiffsqrd: 1.52 
Org mean perf: 1 Pop mean: 1.2 Diffsqrd: 0.04 SumDiffsqrd: 1.56 
Org mean perf: 1 Pop mean: 1.2 Diffsqrd: 0.04 SumDiffsqrd: 1.6 
Stddv: 0.4  StdErr: 0.126491106407
------------------------------------------------------------
 

quartiles: {'mean_threads': 1.2, 'min': 1, 'Generation': 1, 'max': 2, 'gen_size': 10, 'mode': 1, 'stderr': 0.12649110640673517}

2
2
1
1
1
1
1
1
1
1
------------------------------------------------------------
Crossing Generation:

fours [u'1_8_ _ _ _ ', u'1_2_ _ _ _ ']
threes [u'1_7_ _ _ _ ', u'1_1_ _ _ _ ']
twos [u'1_6_ _ _ _ ', u'1_9_ _ _ _ ']
ones [u'1_4_ _ _ _ ', u'1_5_ _ _ _ ']
org1 1_2_ _ _ _ , org2 1_8_ _ _ _ 
crossing org1:1_2_ _ _ _  with org2:1_8_ _ _ _ 

fours []
threes [u'1_7_ _ _ _ ', u'1_1_ _ _ _ ', u'1_2_ _ _ _ ', u'1_8_ _ _ _ ']
twos [u'1_6_ _ _ _ ', u'1_9_ _ _ _ ']
ones [u'1_4_ _ _ _ ', u'1_5_ _ _ _ ']
org1 1_2_ _ _ _ , org2 1_7_ _ _ _ 
crossing org1:1_2_ _ _ _  with org2:1_7_ _ _ _ 

fours []
threes [u'1_1_ _ _ _ ', u'1_8_ _ _ _ ']
twos [u'1_6_ _ _ _ ', u'1_9_ _ _ _ ', u'1_2_ _ _ _ ', u'1_7_ _ _ _ ']
ones [u'1_4_ _ _ _ ', u'1_5_ _ _ _ ']
org1 1_8_ _ _ _ , org2 1_1_ _ _ _ 
crossing org1:1_8_ _ _ _  with org2:1_1_ _ _ _ 

fours []
threes []
twos [u'1_6_ _ _ _ ', u'1_9_ _ _ _ ', u'1_2_ _ _ _ ', u'1_7_ _ _ _ ', u'1_8_ _ _ _ ', u'1_1_ _ _ _ ']
ones [u'1_4_ _ _ _ ', u'1_5_ _ _ _ ']
org1 1_7_ _ _ _ , org2 1_2_ _ _ _ 
crossing org1:1_7_ _ _ _  with org2:1_2_ _ _ _ 

fours []
threes []
twos [u'1_6_ _ _ _ ', u'1_9_ _ _ _ ', u'1_8_ _ _ _ ', u'1_1_ _ _ _ ']
ones [u'1_4_ _ _ _ ', u'1_5_ _ _ _ ', u'1_7_ _ _ _ ', u'1_2_ _ _ _ ']
org1 1_6_ _ _ _ , org2 1_9_ _ _ _ 
crossing org1:1_6_ _ _ _  with org2:1_9_ _ _ _ 

fours []
threes []
twos [u'1_8_ _ _ _ ', u'1_1_ _ _ _ ']
ones [u'1_4_ _ _ _ ', u'1_5_ _ _ _ ', u'1_7_ _ _ _ ', u'1_2_ _ _ _ ', u'1_6_ _ _ _ ', u'1_9_ _ _ _ ']
org1 1_1_ _ _ _ , org2 1_8_ _ _ _ 
crossing org1:1_1_ _ _ _  with org2:1_8_ _ _ _ 

fours []
threes []
twos []
ones [u'1_4_ _ _ _ ', u'1_5_ _ _ _ ', u'1_7_ _ _ _ ', u'1_2_ _ _ _ ', u'1_6_ _ _ _ ', u'1_9_ _ _ _ ', u'1_1_ _ _ _ ', u'1_8_ _ _ _ ']
org1 1_7_ _ _ _ , org2 1_4_ _ _ _ 
crossing org1:1_7_ _ _ _  with org2:1_4_ _ _ _ 

fours []
threes []
twos []
ones [u'1_5_ _ _ _ ', u'1_2_ _ _ _ ', u'1_6_ _ _ _ ', u'1_9_ _ _ _ ', u'1_1_ _ _ _ ', u'1_8_ _ _ _ ']
org1 1_9_ _ _ _ , org2 1_6_ _ _ _ 
crossing org1:1_9_ _ _ _  with org2:1_6_ _ _ _ 

fours []
threes []
twos []
ones [u'1_5_ _ _ _ ', u'1_2_ _ _ _ ', u'1_1_ _ _ _ ', u'1_8_ _ _ _ ']
org1 1_5_ _ _ _ , org2 1_2_ _ _ _ 
crossing org1:1_5_ _ _ _  with org2:1_2_ _ _ _ 

fours []
threes []
twos []
ones [u'1_1_ _ _ _ ', u'1_8_ _ _ _ ']
org1 1_1_ _ _ _ , org2 1_8_ _ _ _ 
crossing org1:1_1_ _ _ _  with org2:1_8_ _ _ _ 


Number of Orgs in new gen: 10
Active Threads per org:

File 2_6_1_7_1_4
thread len.: 0
thread len.: 0

thread count 0

File 2_2_1_1_1_8
thread len.: 0
thread len.: 0

thread count 0

File 2_1_1_2_1_7
thread len.: 0
thread len.: 0

thread count 0

File 2_0_1_2_1_8
thread len.: 0
thread len.: 0

thread count 0

File 2_5_1_8_1_1
thread len.: 0
thread len.: 0

thread count 0

File 2_7_1_6_1_9
thread len.: 0
thread len.: 0

thread count 0

File 2_8_1_2_1_5
thread len.: 0
thread len.: 0

thread count 0

File 2_4_1_6_1_9
thread len.: 0
thread len.: 0

thread count 0

File 2_9_1_8_1_1
thread len.: 0
thread len.: 0

thread count 0

File 2_3_1_7_1_2
thread len.: 0
thread len.: 2

thread count 1


 mean performances for each org in population: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]

--------------------------------------------------
Calculating the Std Error of the mean: 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.01 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.02 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.03 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.04 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.05 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.06 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.07 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.08 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.09 
Org mean perf: 1 Pop mean: 0.1 Diffsqrd: 0.81 SumDiffsqrd: 0.9 
Stddv: 0.3  StdErr: 0.0948683298051
------------------------------------------------------------
 

quartiles: {'mean_threads': 0.1, 'min': 0, 'Generation': 2, 'max': 1, 'gen_size': 10, 'mode': 0, 'stderr': 0.09486832980505139}

1
0
0
0
0
0
0
0
0
0
------------------------------------------------------------
Crossing Generation:

fours [u'2_3_1_7_1_2', u'2_6_1_7_1_4']
threes [u'2_2_1_1_1_8', u'2_1_1_2_1_7']
twos [u'2_0_1_2_1_8', u'2_5_1_8_1_1']
ones [u'2_7_1_6_1_9', u'2_8_1_2_1_5']
org1 2_3_1_7_1_2, org2 2_6_1_7_1_4
crossing org1:2_3_1_7_1_2 with org2:2_6_1_7_1_4

fours []
threes [u'2_2_1_1_1_8', u'2_1_1_2_1_7', u'2_3_1_7_1_2', u'2_6_1_7_1_4']
twos [u'2_0_1_2_1_8', u'2_5_1_8_1_1']
ones [u'2_7_1_6_1_9', u'2_8_1_2_1_5']
org1 2_2_1_1_1_8, org2 2_3_1_7_1_2
crossing org1:2_2_1_1_1_8 with org2:2_3_1_7_1_2

fours []
threes [u'2_1_1_2_1_7', u'2_6_1_7_1_4']
twos [u'2_0_1_2_1_8', u'2_5_1_8_1_1', u'2_2_1_1_1_8', u'2_3_1_7_1_2']
ones [u'2_7_1_6_1_9', u'2_8_1_2_1_5']
org1 2_6_1_7_1_4, org2 2_1_1_2_1_7
crossing org1:2_6_1_7_1_4 with org2:2_1_1_2_1_7

fours []
threes []
twos [u'2_0_1_2_1_8', u'2_5_1_8_1_1', u'2_2_1_1_1_8', u'2_3_1_7_1_2', u'2_6_1_7_1_4', u'2_1_1_2_1_7']
ones [u'2_7_1_6_1_9', u'2_8_1_2_1_5']
org1 2_0_1_2_1_8, org2 2_5_1_8_1_1
crossing org1:2_0_1_2_1_8 with org2:2_5_1_8_1_1

fours []
threes []
twos [u'2_2_1_1_1_8', u'2_3_1_7_1_2', u'2_6_1_7_1_4', u'2_1_1_2_1_7']
ones [u'2_7_1_6_1_9', u'2_8_1_2_1_5', u'2_0_1_2_1_8', u'2_5_1_8_1_1']
org1 2_1_1_2_1_7, org2 2_6_1_7_1_4
crossing org1:2_1_1_2_1_7 with org2:2_6_1_7_1_4

fours []
threes []
twos [u'2_2_1_1_1_8', u'2_3_1_7_1_2']
ones [u'2_7_1_6_1_9', u'2_8_1_2_1_5', u'2_0_1_2_1_8', u'2_5_1_8_1_1', u'2_1_1_2_1_7', u'2_6_1_7_1_4']
org1 2_3_1_7_1_2, org2 2_2_1_1_1_8
crossing org1:2_3_1_7_1_2 with org2:2_2_1_1_1_8

fours []
threes []
twos []
ones [u'2_7_1_6_1_9', u'2_8_1_2_1_5', u'2_0_1_2_1_8', u'2_5_1_8_1_1', u'2_1_1_2_1_7', u'2_6_1_7_1_4', u'2_3_1_7_1_2', u'2_2_1_1_1_8']
org1 2_1_1_2_1_7, org2 2_2_1_1_1_8
crossing org1:2_1_1_2_1_7 with org2:2_2_1_1_1_8

fours []
threes []
twos []
ones [u'2_7_1_6_1_9', u'2_8_1_2_1_5', u'2_0_1_2_1_8', u'2_5_1_8_1_1', u'2_6_1_7_1_4', u'2_3_1_7_1_2']
org1 2_7_1_6_1_9, org2 2_3_1_7_1_2
crossing org1:2_7_1_6_1_9 with org2:2_3_1_7_1_2

fours []
threes []
twos []
ones [u'2_8_1_2_1_5', u'2_0_1_2_1_8', u'2_5_1_8_1_1', u'2_6_1_7_1_4']
org1 2_5_1_8_1_1, org2 2_0_1_2_1_8
crossing org1:2_5_1_8_1_1 with org2:2_0_1_2_1_8

fours []
threes []
twos []
ones [u'2_8_1_2_1_5', u'2_6_1_7_1_4']
org1 2_8_1_2_1_5, org2 2_6_1_7_1_4
crossing org1:2_8_1_2_1_5 with org2:2_6_1_7_1_4


Number of Orgs in new gen: 10
Active Threads per org:

File 3_6_2_2_2_1
thread len.: 0
thread len.: 0

thread count 0

File 3_4_2_1_2_6
thread len.: 0
thread len.: 0

thread count 0

File 3_2_2_6_2_1
thread len.: 0
thread len.: 2

thread count 1

File 3_8_2_5_2_0
thread len.: 0
thread len.: 0

thread count 0

File 3_5_2_2_2_3
thread len.: 0
thread len.: 0

thread count 0

File 3_1_2_2_2_3
thread len.: 0
thread len.: 0

thread count 0

File 3_3_2_5_2_0
thread len.: 0
thread len.: 0

thread count 0

File 3_9_2_8_2_6
thread len.: 0
thread len.: 0

thread count 0

File 3_7_2_7_2_3
thread len.: 0
thread len.: 0

thread count 0

File 3_0_2_3_2_6
thread len.: 0
thread len.: 0

thread count 0


 mean performances for each org in population: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]

--------------------------------------------------
Calculating the Std Error of the mean: 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.01 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.02 
Org mean perf: 1 Pop mean: 0.1 Diffsqrd: 0.81 SumDiffsqrd: 0.83 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.84 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.85 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.86 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.87 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.88 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.89 
Org mean perf: 0 Pop mean: 0.1 Diffsqrd: 0.01 SumDiffsqrd: 0.9 
Stddv: 0.3  StdErr: 0.0948683298051
------------------------------------------------------------
 

quartiles: {'mean_threads': 0.1, 'min': 0, 'Generation': 3, 'max': 1, 'gen_size': 10, 'mode': 0, 'stderr': 0.09486832980505139}

1
0
0
0
0
0
0
0
0
0
------------------------------------------------------------
Crossing Generation:

fours [u'3_2_2_6_2_1', u'3_6_2_2_2_1']
threes [u'3_4_2_1_2_6', u'3_8_2_5_2_0']
twos [u'3_5_2_2_2_3', u'3_1_2_2_2_3']
ones [u'3_3_2_5_2_0', u'3_9_2_8_2_6']
org1 3_6_2_2_2_1, org2 3_2_2_6_2_1
crossing org1:3_6_2_2_2_1 with org2:3_2_2_6_2_1

fours []
threes [u'3_4_2_1_2_6', u'3_8_2_5_2_0', u'3_6_2_2_2_1', u'3_2_2_6_2_1']
twos [u'3_5_2_2_2_3', u'3_1_2_2_2_3']
ones [u'3_3_2_5_2_0', u'3_9_2_8_2_6']
org1 3_4_2_1_2_6, org2 3_8_2_5_2_0
crossing org1:3_4_2_1_2_6 with org2:3_8_2_5_2_0

fours []
threes [u'3_6_2_2_2_1', u'3_2_2_6_2_1']
twos [u'3_5_2_2_2_3', u'3_1_2_2_2_3', u'3_4_2_1_2_6', u'3_8_2_5_2_0']
ones [u'3_3_2_5_2_0', u'3_9_2_8_2_6']
org1 3_2_2_6_2_1, org2 3_6_2_2_2_1
crossing org1:3_2_2_6_2_1 with org2:3_6_2_2_2_1

fours []
threes []
twos [u'3_5_2_2_2_3', u'3_1_2_2_2_3', u'3_4_2_1_2_6', u'3_8_2_5_2_0', u'3_2_2_6_2_1', u'3_6_2_2_2_1']
ones [u'3_3_2_5_2_0', u'3_9_2_8_2_6']
org1 3_8_2_5_2_0, org2 3_1_2_2_2_3
crossing org1:3_8_2_5_2_0 with org2:3_1_2_2_2_3

fours []
threes []
twos [u'3_5_2_2_2_3', u'3_4_2_1_2_6', u'3_2_2_6_2_1', u'3_6_2_2_2_1']
ones [u'3_3_2_5_2_0', u'3_9_2_8_2_6', u'3_8_2_5_2_0', u'3_1_2_2_2_3']
org1 3_6_2_2_2_1, org2 3_4_2_1_2_6
crossing org1:3_6_2_2_2_1 with org2:3_4_2_1_2_6

fours []
threes []
twos [u'3_5_2_2_2_3', u'3_2_2_6_2_1']
ones [u'3_3_2_5_2_0', u'3_9_2_8_2_6', u'3_8_2_5_2_0', u'3_1_2_2_2_3', u'3_6_2_2_2_1', u'3_4_2_1_2_6']
org1 3_2_2_6_2_1, org2 3_5_2_2_2_3
crossing org1:3_2_2_6_2_1 with org2:3_5_2_2_2_3

fours []
threes []
twos []
ones [u'3_3_2_5_2_0', u'3_9_2_8_2_6', u'3_8_2_5_2_0', u'3_1_2_2_2_3', u'3_6_2_2_2_1', u'3_4_2_1_2_6', u'3_2_2_6_2_1', u'3_5_2_2_2_3']
org1 3_6_2_2_2_1, org2 3_4_2_1_2_6
crossing org1:3_6_2_2_2_1 with org2:3_4_2_1_2_6

fours []
threes []
twos []
ones [u'3_3_2_5_2_0', u'3_9_2_8_2_6', u'3_8_2_5_2_0', u'3_1_2_2_2_3', u'3_2_2_6_2_1', u'3_5_2_2_2_3']
org1 3_3_2_5_2_0, org2 3_8_2_5_2_0
crossing org1:3_3_2_5_2_0 with org2:3_8_2_5_2_0

Char mutation at index: 15
0 --> 1
fours []
threes []
twos []
ones [u'3_9_2_8_2_6', u'3_1_2_2_2_3', u'3_2_2_6_2_1', u'3_5_2_2_2_3']
org1 3_1_2_2_2_3, org2 3_2_2_6_2_1
crossing org1:3_1_2_2_2_3 with org2:3_2_2_6_2_1

fours []
threes []
twos []
ones [u'3_9_2_8_2_6', u'3_5_2_2_2_3']
org1 3_9_2_8_2_6, org2 3_5_2_2_2_3
crossing org1:3_9_2_8_2_6 with org2:3_5_2_2_2_3


Number of Orgs in new gen: 10
Active Threads per org:

File 4_6_3_6_3_4
thread len.: 0
thread len.: 0

thread count 0

File 4_0_3_6_3_2
thread len.: 0
thread len.: 0

thread count 0

File 4_1_3_4_3_8
thread len.: 0
thread len.: 0

thread count 0

File 4_2_3_2_3_6
thread len.: 0
thread len.: 0

thread count 0

File 4_9_3_5_3_9
thread len.: 0
thread len.: 0

thread count 0

File 4_7_3_8_3_3
thread len.: 0
thread len.: 0

thread count 0

File 4_5_3_2_3_5
thread len.: 0
thread len.: 0

thread count 0

File 4_8_3_2_3_1
thread len.: 0
thread len.: 0

thread count 0

File 4_3_3_8_3_1
thread len.: 0
thread len.: 0

thread count 0

File 4_4_3_6_3_4
thread len.: 0
thread len.: 0

thread count 0


 mean performances for each org in population: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

--------------------------------------------------
Calculating the Std Error of the mean: 
Org mean perf: 0 Pop mean: 0.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 0 Pop mean: 0.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 0 Pop mean: 0.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 0 Pop mean: 0.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 0 Pop mean: 0.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 0 Pop mean: 0.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 0 Pop mean: 0.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 0 Pop mean: 0.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 0 Pop mean: 0.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 0 Pop mean: 0.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Stddv: 0.0  StdErr: 0.0
------------------------------------------------------------
 

quartiles: {'mean_threads': 0.0, 'min': 0, 'Generation': 4, 'max': 0, 'gen_size': 10, 'mode': 0, 'stderr': 0.0}

0
0
0
0
0
0
0
0
0
0
------------------------------------------------------------
Crossing Generation:

fours [u'4_6_3_6_3_4', u'4_0_3_6_3_2']
threes [u'4_1_3_4_3_8', u'4_2_3_2_3_6']
twos [u'4_9_3_5_3_9', u'4_7_3_8_3_3']
ones [u'4_5_3_2_3_5', u'4_8_3_2_3_1']
org1 4_0_3_6_3_2, org2 4_6_3_6_3_4
crossing org1:4_0_3_6_3_2 with org2:4_6_3_6_3_4

fours []
threes [u'4_1_3_4_3_8', u'4_2_3_2_3_6', u'4_0_3_6_3_2', u'4_6_3_6_3_4']
twos [u'4_9_3_5_3_9', u'4_7_3_8_3_3']
ones [u'4_5_3_2_3_5', u'4_8_3_2_3_1']
org1 4_2_3_2_3_6, org2 4_6_3_6_3_4
crossing org1:4_2_3_2_3_6 with org2:4_6_3_6_3_4

fours []
threes [u'4_1_3_4_3_8', u'4_0_3_6_3_2']
twos [u'4_9_3_5_3_9', u'4_7_3_8_3_3', u'4_2_3_2_3_6', u'4_6_3_6_3_4']
ones [u'4_5_3_2_3_5', u'4_8_3_2_3_1']
org1 4_0_3_6_3_2, org2 4_1_3_4_3_8
crossing org1:4_0_3_6_3_2 with org2:4_1_3_4_3_8

fours []
threes []
twos [u'4_9_3_5_3_9', u'4_7_3_8_3_3', u'4_2_3_2_3_6', u'4_6_3_6_3_4', u'4_0_3_6_3_2', u'4_1_3_4_3_8']
ones [u'4_5_3_2_3_5', u'4_8_3_2_3_1']
org1 4_9_3_5_3_9, org2 4_1_3_4_3_8
crossing org1:4_9_3_5_3_9 with org2:4_1_3_4_3_8

fours []
threes []
twos [u'4_7_3_8_3_3', u'4_2_3_2_3_6', u'4_6_3_6_3_4', u'4_0_3_6_3_2']
ones [u'4_5_3_2_3_5', u'4_8_3_2_3_1', u'4_9_3_5_3_9', u'4_1_3_4_3_8']
org1 4_2_3_2_3_6, org2 4_6_3_6_3_4
crossing org1:4_2_3_2_3_6 with org2:4_6_3_6_3_4

fours []
threes []
twos [u'4_7_3_8_3_3', u'4_0_3_6_3_2']
ones [u'4_5_3_2_3_5', u'4_8_3_2_3_1', u'4_9_3_5_3_9', u'4_1_3_4_3_8', u'4_2_3_2_3_6', u'4_6_3_6_3_4']
org1 4_7_3_8_3_3, org2 4_0_3_6_3_2
crossing org1:4_7_3_8_3_3 with org2:4_0_3_6_3_2

fours []
threes []
twos []
ones [u'4_5_3_2_3_5', u'4_8_3_2_3_1', u'4_9_3_5_3_9', u'4_1_3_4_3_8', u'4_2_3_2_3_6', u'4_6_3_6_3_4', u'4_7_3_8_3_3', u'4_0_3_6_3_2']
org1 4_0_3_6_3_2, org2 4_8_3_2_3_1
crossing org1:4_0_3_6_3_2 with org2:4_8_3_2_3_1

fours []
threes []
twos []
ones [u'4_5_3_2_3_5', u'4_9_3_5_3_9', u'4_1_3_4_3_8', u'4_2_3_2_3_6', u'4_6_3_6_3_4', u'4_7_3_8_3_3']
org1 4_7_3_8_3_3, org2 4_6_3_6_3_4
crossing org1:4_7_3_8_3_3 with org2:4_6_3_6_3_4

fours []
threes []
twos []
ones [u'4_5_3_2_3_5', u'4_9_3_5_3_9', u'4_1_3_4_3_8', u'4_2_3_2_3_6']
org1 4_2_3_2_3_6, org2 4_5_3_2_3_5
crossing org1:4_2_3_2_3_6 with org2:4_5_3_2_3_5

fours []
threes []
twos []
ones [u'4_9_3_5_3_9', u'4_1_3_4_3_8']
org1 4_9_3_5_3_9, org2 4_1_3_4_3_8
crossing org1:4_9_3_5_3_9 with org2:4_1_3_4_3_8


Number of Orgs in new gen: 10
Active Threads per org:

File 5_3_4_1_4_9
thread len.: 0
thread len.: 0

thread count 0

File 5_9_4_9_4_1
thread len.: 4
thread len.: 2

thread count 2

File 5_6_4_0_4_8
thread len.: 0
thread len.: 0

thread count 0

File 5_8_4_2_4_5
thread len.: 0
thread len.: 0

thread count 0

File 5_5_4_7_4_0
thread len.: 0
thread len.: 0

thread count 0

File 5_7_4_6_4_7
thread len.: 4
thread len.: 2

thread count 2

File 5_2_4_0_4_1
thread len.: 4
thread len.: 2

thread count 2

File 5_1_4_2_4_6
thread len.: 0
thread len.: 0

thread count 0

File 5_0_4_0_4_6
thread len.: 0
thread len.: 0

thread count 0

File 5_4_4_2_4_6
thread len.: 0
thread len.: 0

thread count 0


 mean performances for each org in population: [0, 2, 0, 0, 0, 2, 2, 0, 0, 0]

--------------------------------------------------
Calculating the Std Error of the mean: 
Org mean perf: 0 Pop mean: 0.6 Diffsqrd: 0.36 SumDiffsqrd: 0.36 
Org mean perf: 2 Pop mean: 0.6 Diffsqrd: 1.96 SumDiffsqrd: 2.32 
Org mean perf: 0 Pop mean: 0.6 Diffsqrd: 0.36 SumDiffsqrd: 2.68 
Org mean perf: 0 Pop mean: 0.6 Diffsqrd: 0.36 SumDiffsqrd: 3.04 
Org mean perf: 0 Pop mean: 0.6 Diffsqrd: 0.36 SumDiffsqrd: 3.4 
Org mean perf: 2 Pop mean: 0.6 Diffsqrd: 1.96 SumDiffsqrd: 5.36 
Org mean perf: 2 Pop mean: 0.6 Diffsqrd: 1.96 SumDiffsqrd: 7.32 
Org mean perf: 0 Pop mean: 0.6 Diffsqrd: 0.36 SumDiffsqrd: 7.68 
Org mean perf: 0 Pop mean: 0.6 Diffsqrd: 0.36 SumDiffsqrd: 8.04 
Org mean perf: 0 Pop mean: 0.6 Diffsqrd: 0.36 SumDiffsqrd: 8.4 
Stddv: 0.916515138991  StdErr: 0.289827534924
------------------------------------------------------------
 

quartiles: {'mean_threads': 0.6, 'min': 0, 'Generation': 5, 'max': 2, 'gen_size': 10, 'mode': 0, 'stderr': 0.2898275349237887}

2
2
2
0
0
0
0
0
0
0
------------------------------------------------------------
Crossing Generation:

fours [u'5_9_4_9_4_1', u'5_7_4_6_4_7']
threes [u'5_2_4_0_4_1', u'5_3_4_1_4_9']
twos [u'5_6_4_0_4_8', u'5_8_4_2_4_5']
ones [u'5_5_4_7_4_0', u'5_1_4_2_4_6']
org1 5_9_4_9_4_1, org2 5_7_4_6_4_7
crossing org1:5_9_4_9_4_1 with org2:5_7_4_6_4_7

fours []
threes [u'5_2_4_0_4_1', u'5_3_4_1_4_9', u'5_9_4_9_4_1', u'5_7_4_6_4_7']
twos [u'5_6_4_0_4_8', u'5_8_4_2_4_5']
ones [u'5_5_4_7_4_0', u'5_1_4_2_4_6']
org1 5_2_4_0_4_1, org2 5_3_4_1_4_9
crossing org1:5_2_4_0_4_1 with org2:5_3_4_1_4_9

fours []
threes [u'5_9_4_9_4_1', u'5_7_4_6_4_7']
twos [u'5_6_4_0_4_8', u'5_8_4_2_4_5', u'5_2_4_0_4_1', u'5_3_4_1_4_9']
ones [u'5_5_4_7_4_0', u'5_1_4_2_4_6']
org1 5_9_4_9_4_1, org2 5_7_4_6_4_7
crossing org1:5_9_4_9_4_1 with org2:5_7_4_6_4_7

Char mutation at index: 377
0 --> 1
fours []
threes []
twos [u'5_6_4_0_4_8', u'5_8_4_2_4_5', u'5_2_4_0_4_1', u'5_3_4_1_4_9', u'5_9_4_9_4_1', u'5_7_4_6_4_7']
ones [u'5_5_4_7_4_0', u'5_1_4_2_4_6']
org1 5_9_4_9_4_1, org2 5_3_4_1_4_9
crossing org1:5_9_4_9_4_1 with org2:5_3_4_1_4_9

fours []
threes []
twos [u'5_6_4_0_4_8', u'5_8_4_2_4_5', u'5_2_4_0_4_1', u'5_7_4_6_4_7']
ones [u'5_5_4_7_4_0', u'5_1_4_2_4_6', u'5_9_4_9_4_1', u'5_3_4_1_4_9']
org1 5_6_4_0_4_8, org2 5_7_4_6_4_7
crossing org1:5_6_4_0_4_8 with org2:5_7_4_6_4_7

fours []
threes []
twos [u'5_8_4_2_4_5', u'5_2_4_0_4_1']
ones [u'5_5_4_7_4_0', u'5_1_4_2_4_6', u'5_9_4_9_4_1', u'5_3_4_1_4_9', u'5_6_4_0_4_8', u'5_7_4_6_4_7']
org1 5_2_4_0_4_1, org2 5_8_4_2_4_5
crossing org1:5_2_4_0_4_1 with org2:5_8_4_2_4_5

fours []
threes []
twos []
ones [u'5_5_4_7_4_0', u'5_1_4_2_4_6', u'5_9_4_9_4_1', u'5_3_4_1_4_9', u'5_6_4_0_4_8', u'5_7_4_6_4_7', u'5_2_4_0_4_1', u'5_8_4_2_4_5']
org1 5_2_4_0_4_1, org2 5_1_4_2_4_6
crossing org1:5_2_4_0_4_1 with org2:5_1_4_2_4_6

fours []
threes []
twos []
ones [u'5_5_4_7_4_0', u'5_9_4_9_4_1', u'5_3_4_1_4_9', u'5_6_4_0_4_8', u'5_7_4_6_4_7', u'5_8_4_2_4_5']
org1 5_5_4_7_4_0, org2 5_8_4_2_4_5
crossing org1:5_5_4_7_4_0 with org2:5_8_4_2_4_5

fours []
threes []
twos []
ones [u'5_9_4_9_4_1', u'5_3_4_1_4_9', u'5_6_4_0_4_8', u'5_7_4_6_4_7']
org1 5_3_4_1_4_9, org2 5_7_4_6_4_7
crossing org1:5_3_4_1_4_9 with org2:5_7_4_6_4_7

fours []
threes []
twos []
ones [u'5_9_4_9_4_1', u'5_6_4_0_4_8']
org1 5_9_4_9_4_1, org2 5_6_4_0_4_8
crossing org1:5_9_4_9_4_1 with org2:5_6_4_0_4_8

Char mutation at index: 163
1 --> 0

Number of Orgs in new gen: 10
Active Threads per org:

File 6_3_5_9_5_3
thread len.: 4
thread len.: 2

thread count 2

File 6_9_5_6_5_9
thread len.: 4
thread len.: 2

thread count 2

File 6_7_5_8_5_5
thread len.: 0
thread len.: 2

thread count 1

File 6_0_5_7_5_9
thread len.: 4
thread len.: 2

thread count 2

File 6_8_5_3_5_7
thread len.: 0
thread len.: 0

thread count 0

File 6_1_5_2_5_3
thread len.: 4
thread len.: 2

thread count 2

File 6_2_5_7_5_9
thread len.: 4
thread len.: 2

thread count 2

File 6_6_5_1_5_2
thread len.: 0
thread len.: 2

thread count 1

File 6_5_5_8_5_2
thread len.: 0
thread len.: 2

thread count 1

File 6_4_5_7_5_6
thread len.: 4
thread len.: 2

thread count 2


 mean performances for each org in population: [2, 2, 1, 2, 0, 2, 2, 1, 1, 2]

--------------------------------------------------
Calculating the Std Error of the mean: 
Org mean perf: 2 Pop mean: 1.5 Diffsqrd: 0.25 SumDiffsqrd: 0.25 
Org mean perf: 2 Pop mean: 1.5 Diffsqrd: 0.25 SumDiffsqrd: 0.5 
Org mean perf: 1 Pop mean: 1.5 Diffsqrd: 0.25 SumDiffsqrd: 0.75 
Org mean perf: 2 Pop mean: 1.5 Diffsqrd: 0.25 SumDiffsqrd: 1.0 
Org mean perf: 0 Pop mean: 1.5 Diffsqrd: 2.25 SumDiffsqrd: 3.25 
Org mean perf: 2 Pop mean: 1.5 Diffsqrd: 0.25 SumDiffsqrd: 3.5 
Org mean perf: 2 Pop mean: 1.5 Diffsqrd: 0.25 SumDiffsqrd: 3.75 
Org mean perf: 1 Pop mean: 1.5 Diffsqrd: 0.25 SumDiffsqrd: 4.0 
Org mean perf: 1 Pop mean: 1.5 Diffsqrd: 0.25 SumDiffsqrd: 4.25 
Org mean perf: 2 Pop mean: 1.5 Diffsqrd: 0.25 SumDiffsqrd: 4.5 
Stddv: 0.67082039325  StdErr: 0.212132034356
------------------------------------------------------------
 

quartiles: {'mean_threads': 1.5, 'min': 0, 'Generation': 6, 'max': 2, 'gen_size': 10, 'mode': 2, 'stderr': 0.21213203435596426}

2
2
2
2
2
2
1
1
1
0
------------------------------------------------------------
Crossing Generation:

fours [u'6_3_5_9_5_3', u'6_9_5_6_5_9']
threes [u'6_0_5_7_5_9', u'6_1_5_2_5_3']
twos [u'6_2_5_7_5_9', u'6_4_5_7_5_6']
ones [u'6_7_5_8_5_5', u'6_6_5_1_5_2']
org1 6_3_5_9_5_3, org2 6_9_5_6_5_9
crossing org1:6_3_5_9_5_3 with org2:6_9_5_6_5_9

fours []
threes [u'6_0_5_7_5_9', u'6_1_5_2_5_3', u'6_3_5_9_5_3', u'6_9_5_6_5_9']
twos [u'6_2_5_7_5_9', u'6_4_5_7_5_6']
ones [u'6_7_5_8_5_5', u'6_6_5_1_5_2']
org1 6_3_5_9_5_3, org2 6_9_5_6_5_9
crossing org1:6_3_5_9_5_3 with org2:6_9_5_6_5_9

fours []
threes [u'6_0_5_7_5_9', u'6_1_5_2_5_3']
twos [u'6_2_5_7_5_9', u'6_4_5_7_5_6', u'6_3_5_9_5_3', u'6_9_5_6_5_9']
ones [u'6_7_5_8_5_5', u'6_6_5_1_5_2']
org1 6_1_5_2_5_3, org2 6_0_5_7_5_9
crossing org1:6_1_5_2_5_3 with org2:6_0_5_7_5_9

fours []
threes []
twos [u'6_2_5_7_5_9', u'6_4_5_7_5_6', u'6_3_5_9_5_3', u'6_9_5_6_5_9', u'6_1_5_2_5_3', u'6_0_5_7_5_9']
ones [u'6_7_5_8_5_5', u'6_6_5_1_5_2']
org1 6_2_5_7_5_9, org2 6_4_5_7_5_6
crossing org1:6_2_5_7_5_9 with org2:6_4_5_7_5_6

fours []
threes []
twos [u'6_3_5_9_5_3', u'6_9_5_6_5_9', u'6_1_5_2_5_3', u'6_0_5_7_5_9']
ones [u'6_7_5_8_5_5', u'6_6_5_1_5_2', u'6_2_5_7_5_9', u'6_4_5_7_5_6']
org1 6_1_5_2_5_3, org2 6_0_5_7_5_9
crossing org1:6_1_5_2_5_3 with org2:6_0_5_7_5_9

fours []
threes []
twos [u'6_3_5_9_5_3', u'6_9_5_6_5_9']
ones [u'6_7_5_8_5_5', u'6_6_5_1_5_2', u'6_2_5_7_5_9', u'6_4_5_7_5_6', u'6_1_5_2_5_3', u'6_0_5_7_5_9']
org1 6_3_5_9_5_3, org2 6_9_5_6_5_9
crossing org1:6_3_5_9_5_3 with org2:6_9_5_6_5_9

fours []
threes []
twos []
ones [u'6_7_5_8_5_5', u'6_6_5_1_5_2', u'6_2_5_7_5_9', u'6_4_5_7_5_6', u'6_1_5_2_5_3', u'6_0_5_7_5_9', u'6_3_5_9_5_3', u'6_9_5_6_5_9']
org1 6_6_5_1_5_2, org2 6_3_5_9_5_3
crossing org1:6_6_5_1_5_2 with org2:6_3_5_9_5_3

fours []
threes []
twos []
ones [u'6_7_5_8_5_5', u'6_2_5_7_5_9', u'6_4_5_7_5_6', u'6_1_5_2_5_3', u'6_0_5_7_5_9', u'6_9_5_6_5_9']
org1 6_2_5_7_5_9, org2 6_7_5_8_5_5
crossing org1:6_2_5_7_5_9 with org2:6_7_5_8_5_5

fours []
threes []
twos []
ones [u'6_4_5_7_5_6', u'6_1_5_2_5_3', u'6_0_5_7_5_9', u'6_9_5_6_5_9']
org1 6_4_5_7_5_6, org2 6_9_5_6_5_9
crossing org1:6_4_5_7_5_6 with org2:6_9_5_6_5_9

fours []
threes []
twos []
ones [u'6_1_5_2_5_3', u'6_0_5_7_5_9']
org1 6_1_5_2_5_3, org2 6_0_5_7_5_9
crossing org1:6_1_5_2_5_3 with org2:6_0_5_7_5_9

Char mutation at index: 252
1 --> 0

Number of Orgs in new gen: 10
Active Threads per org:

File 7_9_6_1_6_0
thread len.: 4
thread len.: 2

thread count 2

File 7_6_6_3_6_6
thread len.: 4
thread len.: 2

thread count 2

File 7_4_6_0_6_1
thread len.: 4
thread len.: 2

thread count 2

File 7_2_6_1_6_0
thread len.: 4
thread len.: 2

thread count 2

File 7_3_6_2_6_4
thread len.: 4
thread len.: 2

thread count 2

File 7_1_6_9_6_3
thread len.: 4
thread len.: 2

thread count 2

File 7_8_6_9_6_4
thread len.: 4
thread len.: 2

thread count 2

File 7_7_6_7_6_2
thread len.: 0
thread len.: 2

thread count 1

File 7_0_6_9_6_3
thread len.: 4
thread len.: 2

thread count 2

File 7_5_6_3_6_9
thread len.: 4
thread len.: 2

thread count 2


 mean performances for each org in population: [2, 2, 2, 2, 2, 2, 2, 1, 2, 2]

--------------------------------------------------
Calculating the Std Error of the mean: 
Org mean perf: 2 Pop mean: 1.9 Diffsqrd: 0.01 SumDiffsqrd: 0.01 
Org mean perf: 2 Pop mean: 1.9 Diffsqrd: 0.01 SumDiffsqrd: 0.02 
Org mean perf: 2 Pop mean: 1.9 Diffsqrd: 0.01 SumDiffsqrd: 0.03 
Org mean perf: 2 Pop mean: 1.9 Diffsqrd: 0.01 SumDiffsqrd: 0.04 
Org mean perf: 2 Pop mean: 1.9 Diffsqrd: 0.01 SumDiffsqrd: 0.05 
Org mean perf: 2 Pop mean: 1.9 Diffsqrd: 0.01 SumDiffsqrd: 0.06 
Org mean perf: 2 Pop mean: 1.9 Diffsqrd: 0.01 SumDiffsqrd: 0.07 
Org mean perf: 1 Pop mean: 1.9 Diffsqrd: 0.81 SumDiffsqrd: 0.88 
Org mean perf: 2 Pop mean: 1.9 Diffsqrd: 0.01 SumDiffsqrd: 0.89 
Org mean perf: 2 Pop mean: 1.9 Diffsqrd: 0.01 SumDiffsqrd: 0.9 
Stddv: 0.3  StdErr: 0.0948683298051
------------------------------------------------------------
 

quartiles: {'mean_threads': 1.9, 'min': 1, 'Generation': 7, 'max': 2, 'gen_size': 10, 'mode': 2, 'stderr': 0.09486832980505137}

2
2
2
2
2
2
2
2
2
1
------------------------------------------------------------
Crossing Generation:

fours [u'7_9_6_1_6_0', u'7_6_6_3_6_6']
threes [u'7_4_6_0_6_1', u'7_2_6_1_6_0']
twos [u'7_3_6_2_6_4', u'7_1_6_9_6_3']
ones [u'7_8_6_9_6_4', u'7_0_6_9_6_3']
org1 7_9_6_1_6_0, org2 7_6_6_3_6_6
crossing org1:7_9_6_1_6_0 with org2:7_6_6_3_6_6

fours []
threes [u'7_4_6_0_6_1', u'7_2_6_1_6_0', u'7_9_6_1_6_0', u'7_6_6_3_6_6']
twos [u'7_3_6_2_6_4', u'7_1_6_9_6_3']
ones [u'7_8_6_9_6_4', u'7_0_6_9_6_3']
org1 7_9_6_1_6_0, org2 7_6_6_3_6_6
crossing org1:7_9_6_1_6_0 with org2:7_6_6_3_6_6

fours []
threes [u'7_4_6_0_6_1', u'7_2_6_1_6_0']
twos [u'7_3_6_2_6_4', u'7_1_6_9_6_3', u'7_9_6_1_6_0', u'7_6_6_3_6_6']
ones [u'7_8_6_9_6_4', u'7_0_6_9_6_3']
org1 7_4_6_0_6_1, org2 7_2_6_1_6_0
crossing org1:7_4_6_0_6_1 with org2:7_2_6_1_6_0

fours []
threes []
twos [u'7_3_6_2_6_4', u'7_1_6_9_6_3', u'7_9_6_1_6_0', u'7_6_6_3_6_6', u'7_4_6_0_6_1', u'7_2_6_1_6_0']
ones [u'7_8_6_9_6_4', u'7_0_6_9_6_3']
org1 7_3_6_2_6_4, org2 7_4_6_0_6_1
crossing org1:7_3_6_2_6_4 with org2:7_4_6_0_6_1

fours []
threes []
twos [u'7_1_6_9_6_3', u'7_9_6_1_6_0', u'7_6_6_3_6_6', u'7_2_6_1_6_0']
ones [u'7_8_6_9_6_4', u'7_0_6_9_6_3', u'7_3_6_2_6_4', u'7_4_6_0_6_1']
org1 7_1_6_9_6_3, org2 7_6_6_3_6_6
crossing org1:7_1_6_9_6_3 with org2:7_6_6_3_6_6

fours []
threes []
twos [u'7_9_6_1_6_0', u'7_2_6_1_6_0']
ones [u'7_8_6_9_6_4', u'7_0_6_9_6_3', u'7_3_6_2_6_4', u'7_4_6_0_6_1', u'7_1_6_9_6_3', u'7_6_6_3_6_6']
org1 7_2_6_1_6_0, org2 7_9_6_1_6_0
crossing org1:7_2_6_1_6_0 with org2:7_9_6_1_6_0

fours []
threes []
twos []
ones [u'7_8_6_9_6_4', u'7_0_6_9_6_3', u'7_3_6_2_6_4', u'7_4_6_0_6_1', u'7_1_6_9_6_3', u'7_6_6_3_6_6', u'7_2_6_1_6_0', u'7_9_6_1_6_0']
org1 7_8_6_9_6_4, org2 7_9_6_1_6_0
crossing org1:7_8_6_9_6_4 with org2:7_9_6_1_6_0

fours []
threes []
twos []
ones [u'7_0_6_9_6_3', u'7_3_6_2_6_4', u'7_4_6_0_6_1', u'7_1_6_9_6_3', u'7_6_6_3_6_6', u'7_2_6_1_6_0']
org1 7_4_6_0_6_1, org2 7_3_6_2_6_4
crossing org1:7_4_6_0_6_1 with org2:7_3_6_2_6_4

fours []
threes []
twos []
ones [u'7_0_6_9_6_3', u'7_1_6_9_6_3', u'7_6_6_3_6_6', u'7_2_6_1_6_0']
org1 7_0_6_9_6_3, org2 7_1_6_9_6_3
crossing org1:7_0_6_9_6_3 with org2:7_1_6_9_6_3

fours []
threes []
twos []
ones [u'7_6_6_3_6_6', u'7_2_6_1_6_0']
org1 7_6_6_3_6_6, org2 7_2_6_1_6_0
crossing org1:7_6_6_3_6_6 with org2:7_2_6_1_6_0


Number of Orgs in new gen: 10
Active Threads per org:

File 8_5_7_2_7_9
thread len.: 4
thread len.: 2

thread count 2

File 8_7_7_4_7_3
thread len.: 4
thread len.: 2

thread count 2

File 8_3_7_3_7_4
thread len.: 4
thread len.: 2

thread count 2

File 8_6_7_8_7_9
thread len.: 4
thread len.: 2

thread count 2

File 8_2_7_2_7_4
thread len.: 4
thread len.: 2

thread count 2

File 8_9_7_6_7_2
thread len.: 4
thread len.: 2

thread count 2

File 8_0_7_9_7_6
thread len.: 4
thread len.: 2

thread count 2

File 8_1_7_9_7_6
thread len.: 4
thread len.: 2

thread count 2

File 8_8_7_1_7_0
thread len.: 4
thread len.: 2

thread count 2

File 8_4_7_6_7_1
thread len.: 4
thread len.: 2

thread count 2


 mean performances for each org in population: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]

--------------------------------------------------
Calculating the Std Error of the mean: 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Stddv: 0.0  StdErr: 0.0
------------------------------------------------------------
 

quartiles: {'mean_threads': 2.0, 'min': 2, 'Generation': 8, 'max': 2, 'gen_size': 10, 'mode': 2, 'stderr': 0.0}

2
2
2
2
2
2
2
2
2
2
------------------------------------------------------------
Crossing Generation:

fours [u'8_5_7_2_7_9', u'8_7_7_4_7_3']
threes [u'8_3_7_3_7_4', u'8_6_7_8_7_9']
twos [u'8_2_7_2_7_4', u'8_9_7_6_7_2']
ones [u'8_0_7_9_7_6', u'8_1_7_9_7_6']
org1 8_5_7_2_7_9, org2 8_7_7_4_7_3
crossing org1:8_5_7_2_7_9 with org2:8_7_7_4_7_3

fours []
threes [u'8_3_7_3_7_4', u'8_6_7_8_7_9', u'8_5_7_2_7_9', u'8_7_7_4_7_3']
twos [u'8_2_7_2_7_4', u'8_9_7_6_7_2']
ones [u'8_0_7_9_7_6', u'8_1_7_9_7_6']
org1 8_6_7_8_7_9, org2 8_5_7_2_7_9
crossing org1:8_6_7_8_7_9 with org2:8_5_7_2_7_9

fours []
threes [u'8_3_7_3_7_4', u'8_7_7_4_7_3']
twos [u'8_2_7_2_7_4', u'8_9_7_6_7_2', u'8_6_7_8_7_9', u'8_5_7_2_7_9']
ones [u'8_0_7_9_7_6', u'8_1_7_9_7_6']
org1 8_3_7_3_7_4, org2 8_7_7_4_7_3
crossing org1:8_3_7_3_7_4 with org2:8_7_7_4_7_3

fours []
threes []
twos [u'8_2_7_2_7_4', u'8_9_7_6_7_2', u'8_6_7_8_7_9', u'8_5_7_2_7_9', u'8_3_7_3_7_4', u'8_7_7_4_7_3']
ones [u'8_0_7_9_7_6', u'8_1_7_9_7_6']
org1 8_7_7_4_7_3, org2 8_3_7_3_7_4
crossing org1:8_7_7_4_7_3 with org2:8_3_7_3_7_4

fours []
threes []
twos [u'8_2_7_2_7_4', u'8_9_7_6_7_2', u'8_6_7_8_7_9', u'8_5_7_2_7_9']
ones [u'8_0_7_9_7_6', u'8_1_7_9_7_6', u'8_7_7_4_7_3', u'8_3_7_3_7_4']
org1 8_2_7_2_7_4, org2 8_6_7_8_7_9
crossing org1:8_2_7_2_7_4 with org2:8_6_7_8_7_9

fours []
threes []
twos [u'8_9_7_6_7_2', u'8_5_7_2_7_9']
ones [u'8_0_7_9_7_6', u'8_1_7_9_7_6', u'8_7_7_4_7_3', u'8_3_7_3_7_4', u'8_2_7_2_7_4', u'8_6_7_8_7_9']
org1 8_5_7_2_7_9, org2 8_9_7_6_7_2
crossing org1:8_5_7_2_7_9 with org2:8_9_7_6_7_2

fours []
threes []
twos []
ones [u'8_0_7_9_7_6', u'8_1_7_9_7_6', u'8_7_7_4_7_3', u'8_3_7_3_7_4', u'8_2_7_2_7_4', u'8_6_7_8_7_9', u'8_5_7_2_7_9', u'8_9_7_6_7_2']
org1 8_5_7_2_7_9, org2 8_9_7_6_7_2
crossing org1:8_5_7_2_7_9 with org2:8_9_7_6_7_2

fours []
threes []
twos []
ones [u'8_0_7_9_7_6', u'8_1_7_9_7_6', u'8_7_7_4_7_3', u'8_3_7_3_7_4', u'8_2_7_2_7_4', u'8_6_7_8_7_9']
org1 8_1_7_9_7_6, org2 8_7_7_4_7_3
crossing org1:8_1_7_9_7_6 with org2:8_7_7_4_7_3

fours []
threes []
twos []
ones [u'8_0_7_9_7_6', u'8_3_7_3_7_4', u'8_2_7_2_7_4', u'8_6_7_8_7_9']
org1 8_0_7_9_7_6, org2 8_6_7_8_7_9
crossing org1:8_0_7_9_7_6 with org2:8_6_7_8_7_9

fours []
threes []
twos []
ones [u'8_3_7_3_7_4', u'8_2_7_2_7_4']
org1 8_2_7_2_7_4, org2 8_3_7_3_7_4
crossing org1:8_2_7_2_7_4 with org2:8_3_7_3_7_4

Crossover_point mutation at index: 271
0 --> 1

Number of Orgs in new gen: 10
Active Threads per org:

File 9_6_8_9_8_5
thread len.: 4
thread len.: 2

thread count 2

File 9_5_8_9_8_5
thread len.: 4
thread len.: 2

thread count 2

File 9_2_8_3_8_7
thread len.: 4
thread len.: 2

thread count 2

File 9_8_8_6_8_0
thread len.: 4
thread len.: 2

thread count 2

File 9_7_8_7_8_1
thread len.: 4
thread len.: 2

thread count 2

File 9_0_8_7_8_5
thread len.: 4
thread len.: 2

thread count 2

File 9_1_8_6_8_5
thread len.: 4
thread len.: 2

thread count 2

File 9_3_8_3_8_7
thread len.: 4
thread len.: 2

thread count 2

File 9_4_8_2_8_6
thread len.: 4
thread len.: 2

thread count 2

File 9_9_8_3_8_2
thread len.: 4
thread len.: 2

thread count 2


 mean performances for each org in population: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]

--------------------------------------------------
Calculating the Std Error of the mean: 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Stddv: 0.0  StdErr: 0.0
------------------------------------------------------------
 

quartiles: {'mean_threads': 2.0, 'min': 2, 'Generation': 9, 'max': 2, 'gen_size': 10, 'mode': 2, 'stderr': 0.0}

2
2
2
2
2
2
2
2
2
2
------------------------------------------------------------
Crossing Generation:

fours [u'9_6_8_9_8_5', u'9_5_8_9_8_5']
threes [u'9_2_8_3_8_7', u'9_8_8_6_8_0']
twos [u'9_7_8_7_8_1', u'9_0_8_7_8_5']
ones [u'9_1_8_6_8_5', u'9_3_8_3_8_7']
org1 9_6_8_9_8_5, org2 9_5_8_9_8_5
crossing org1:9_6_8_9_8_5 with org2:9_5_8_9_8_5

fours []
threes [u'9_2_8_3_8_7', u'9_8_8_6_8_0', u'9_6_8_9_8_5', u'9_5_8_9_8_5']
twos [u'9_7_8_7_8_1', u'9_0_8_7_8_5']
ones [u'9_1_8_6_8_5', u'9_3_8_3_8_7']
org1 9_5_8_9_8_5, org2 9_6_8_9_8_5
crossing org1:9_5_8_9_8_5 with org2:9_6_8_9_8_5

fours []
threes [u'9_2_8_3_8_7', u'9_8_8_6_8_0']
twos [u'9_7_8_7_8_1', u'9_0_8_7_8_5', u'9_5_8_9_8_5', u'9_6_8_9_8_5']
ones [u'9_1_8_6_8_5', u'9_3_8_3_8_7']
org1 9_2_8_3_8_7, org2 9_8_8_6_8_0
crossing org1:9_2_8_3_8_7 with org2:9_8_8_6_8_0

fours []
threes []
twos [u'9_7_8_7_8_1', u'9_0_8_7_8_5', u'9_5_8_9_8_5', u'9_6_8_9_8_5', u'9_2_8_3_8_7', u'9_8_8_6_8_0']
ones [u'9_1_8_6_8_5', u'9_3_8_3_8_7']
org1 9_7_8_7_8_1, org2 9_6_8_9_8_5
crossing org1:9_7_8_7_8_1 with org2:9_6_8_9_8_5

fours []
threes []
twos [u'9_0_8_7_8_5', u'9_5_8_9_8_5', u'9_2_8_3_8_7', u'9_8_8_6_8_0']
ones [u'9_1_8_6_8_5', u'9_3_8_3_8_7', u'9_7_8_7_8_1', u'9_6_8_9_8_5']
org1 9_0_8_7_8_5, org2 9_2_8_3_8_7
crossing org1:9_0_8_7_8_5 with org2:9_2_8_3_8_7

fours []
threes []
twos [u'9_5_8_9_8_5', u'9_8_8_6_8_0']
ones [u'9_1_8_6_8_5', u'9_3_8_3_8_7', u'9_7_8_7_8_1', u'9_6_8_9_8_5', u'9_0_8_7_8_5', u'9_2_8_3_8_7']
org1 9_5_8_9_8_5, org2 9_8_8_6_8_0
crossing org1:9_5_8_9_8_5 with org2:9_8_8_6_8_0

fours []
threes []
twos []
ones [u'9_1_8_6_8_5', u'9_3_8_3_8_7', u'9_7_8_7_8_1', u'9_6_8_9_8_5', u'9_0_8_7_8_5', u'9_2_8_3_8_7', u'9_5_8_9_8_5', u'9_8_8_6_8_0']
org1 9_7_8_7_8_1, org2 9_5_8_9_8_5
crossing org1:9_7_8_7_8_1 with org2:9_5_8_9_8_5

fours []
threes []
twos []
ones [u'9_1_8_6_8_5', u'9_3_8_3_8_7', u'9_6_8_9_8_5', u'9_0_8_7_8_5', u'9_2_8_3_8_7', u'9_8_8_6_8_0']
org1 9_0_8_7_8_5, org2 9_8_8_6_8_0
crossing org1:9_0_8_7_8_5 with org2:9_8_8_6_8_0

fours []
threes []
twos []
ones [u'9_1_8_6_8_5', u'9_3_8_3_8_7', u'9_6_8_9_8_5', u'9_2_8_3_8_7']
org1 9_2_8_3_8_7, org2 9_6_8_9_8_5
crossing org1:9_2_8_3_8_7 with org2:9_6_8_9_8_5

fours []
threes []
twos []
ones [u'9_1_8_6_8_5', u'9_3_8_3_8_7']
org1 9_3_8_3_8_7, org2 9_1_8_6_8_5
crossing org1:9_3_8_3_8_7 with org2:9_1_8_6_8_5


Number of Orgs in new gen: 10
Active Threads per org:

File 10_4_9_2_9_0
thread len.: 4
thread len.: 2

thread count 2

File 10_1_9_5_9_6
thread len.: 4
thread len.: 2

thread count 2

File 10_7_9_8_9_0
thread len.: 4
thread len.: 2

thread count 2

File 10_3_9_6_9_7
thread len.: 4
thread len.: 2

thread count 2

File 10_0_9_5_9_6
thread len.: 4
thread len.: 2

thread count 2

File 10_8_9_6_9_2
thread len.: 4
thread len.: 2

thread count 2

File 10_2_9_2_9_8
thread len.: 4
thread len.: 2

thread count 2

File 10_6_9_5_9_7
thread len.: 4
thread len.: 2

thread count 2

File 10_9_9_3_9_1
thread len.: 4
thread len.: 2

thread count 2

File 10_5_9_8_9_5
thread len.: 4
thread len.: 2

thread count 2


 mean performances for each org in population: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]

--------------------------------------------------
Calculating the Std Error of the mean: 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Org mean perf: 2 Pop mean: 2.0 Diffsqrd: 0.0 SumDiffsqrd: 0.0 
Stddv: 0.0  StdErr: 0.0
------------------------------------------------------------
 

quartiles: {'mean_threads': 2.0, 'min': 2, 'Generation': 10, 'max': 2, 'gen_size': 10, 'mode': 2, 'stderr': 0.0}

2
2
2
2
2
2
2
2
2
2
------------------------------------------------------------
Crossing Generation:

fours [u'10_4_9_2_9_0', u'10_1_9_5_9_6']
threes [u'10_7_9_8_9_0', u'10_3_9_6_9_7']
twos [u'10_0_9_5_9_6', u'10_8_9_6_9_2']
ones [u'10_2_9_2_9_8', u'10_6_9_5_9_7']
org1 10_1_9_5_9_6, org2 10_4_9_2_9_0
crossing org1:10_1_9_5_9_6 with org2:10_4_9_2_9_0

fours []
threes [u'10_7_9_8_9_0', u'10_3_9_6_9_7', u'10_1_9_5_9_6', u'10_4_9_2_9_0']
twos [u'10_0_9_5_9_6', u'10_8_9_6_9_2']
ones [u'10_2_9_2_9_8', u'10_6_9_5_9_7']
org1 10_1_9_5_9_6, org2 10_3_9_6_9_7
crossing org1:10_1_9_5_9_6 with org2:10_3_9_6_9_7

fours []
threes [u'10_7_9_8_9_0', u'10_4_9_2_9_0']
twos [u'10_0_9_5_9_6', u'10_8_9_6_9_2', u'10_1_9_5_9_6', u'10_3_9_6_9_7']
ones [u'10_2_9_2_9_8', u'10_6_9_5_9_7']
org1 10_7_9_8_9_0, org2 10_4_9_2_9_0
crossing org1:10_7_9_8_9_0 with org2:10_4_9_2_9_0

fours []
threes []
twos [u'10_0_9_5_9_6', u'10_8_9_6_9_2', u'10_1_9_5_9_6', u'10_3_9_6_9_7', u'10_7_9_8_9_0', u'10_4_9_2_9_0']
ones [u'10_2_9_2_9_8', u'10_6_9_5_9_7']
org1 10_3_9_6_9_7, org2 10_0_9_5_9_6
crossing org1:10_3_9_6_9_7 with org2:10_0_9_5_9_6

fours []
threes []
twos [u'10_8_9_6_9_2', u'10_1_9_5_9_6', u'10_7_9_8_9_0', u'10_4_9_2_9_0']
ones [u'10_2_9_2_9_8', u'10_6_9_5_9_7', u'10_3_9_6_9_7', u'10_0_9_5_9_6']
org1 10_8_9_6_9_2, org2 10_7_9_8_9_0
crossing org1:10_8_9_6_9_2 with org2:10_7_9_8_9_0

fours []
threes []
twos [u'10_1_9_5_9_6', u'10_4_9_2_9_0']
ones [u'10_2_9_2_9_8', u'10_6_9_5_9_7', u'10_3_9_6_9_7', u'10_0_9_5_9_6', u'10_8_9_6_9_2', u'10_7_9_8_9_0']
org1 10_1_9_5_9_6, org2 10_4_9_2_9_0
crossing org1:10_1_9_5_9_6 with org2:10_4_9_2_9_0

fours []
threes []
twos []
ones [u'10_2_9_2_9_8', u'10_6_9_5_9_7', u'10_3_9_6_9_7', u'10_0_9_5_9_6', u'10_8_9_6_9_2', u'10_7_9_8_9_0', u'10_1_9_5_9_6', u'10_4_9_2_9_0']
org1 10_7_9_8_9_0, org2 10_3_9_6_9_7
crossing org1:10_7_9_8_9_0 with org2:10_3_9_6_9_7

fours []
threes []
twos []
ones [u'10_2_9_2_9_8', u'10_6_9_5_9_7', u'10_0_9_5_9_6', u'10_8_9_6_9_2', u'10_1_9_5_9_6', u'10_4_9_2_9_0']
org1 10_2_9_2_9_8, org2 10_0_9_5_9_6
crossing org1:10_2_9_2_9_8 with org2:10_0_9_5_9_6

fours []
threes []
twos []
ones [u'10_6_9_5_9_7', u'10_8_9_6_9_2', u'10_1_9_5_9_6', u'10_4_9_2_9_0']
org1 10_8_9_6_9_2, org2 10_4_9_2_9_0
crossing org1:10_8_9_6_9_2 with org2:10_4_9_2_9_0

fours []
threes []
twos []
ones [u'10_6_9_5_9_7', u'10_1_9_5_9_6']
org1 10_1_9_5_9_6, org2 10_6_9_5_9_7
crossing org1:10_1_9_5_9_6 with org2:10_6_9_5_9_7


Number of Orgs in new gen: 10
#+end_example

